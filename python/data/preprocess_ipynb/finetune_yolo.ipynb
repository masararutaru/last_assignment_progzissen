{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# YOLOv5モデルのファインチューニング\n",
        "\n",
        "このNotebookでは、COCO事前学習済みYOLOv5nモデルをKaggle OCRデータセットでファインチューニングします。\n",
        "\n",
        "**高速化のため、ローカルストレージ（/content/tmp/）を使用します。**\n",
        "\n",
        "## 処理の流れ\n",
        "1. Google Driveのマウント\n",
        "2. Gitリポジトリのクローン/更新\n",
        "3. 環境変数の設定\n",
        "4. データセットをローカルストレージにコピー（高速化）\n",
        "5. データセットの確認\n",
        "6. 事前学習済みモデルの準備\n",
        "7. 学習設定\n",
        "8. 学習の実行\n",
        "9. 学習結果の確認\n",
        "10. 最良モデルをGoogle Driveに保存\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GPUランタイムとコンピューティングユニットについて\n",
        "\n",
        "**⚠️ 重要: このNotebookは最初からGPUランタイムで実行してください。**\n",
        "\n",
        "- CPUランタイムでデータコピー → GPUランタイムに変更すると、`/content/`配下のデータが消えます\n",
        "- GPUランタイムに変更すると、ランタイムがリセットされ、ローカルストレージのデータが失われます\n",
        "- データコピー中もGPUランタイムが有効なため、コンピューティングユニットが消費されます\n",
        "\n",
        "### GPU/TPUの特徴とコストパフォーマンス比較\n",
        "\n",
        "| デバイス | アーキテクチャ | メモリ | 主な特徴 | 5時間あたりCU消費（推定） | コスパ評価 | YOLOv5適性 |\n",
        "|---------|------------|--------|---------|----------------------|----------|-----------|\n",
        "| **L4** | Ada Lovelace | 24GB | T4の後継、性能向上（FP16: 242 TFLOPS）、低消費電力（72W） | **~10-12 CU** | ⭐⭐⭐⭐⭐ 最良 | ✅ 推奨（最適） |\n",
        "| **T4** | Turing | 16GB | 低コスト、広く利用可能（FP16: 65 TFLOPS）、低消費電力（70W） | **7.44 CU** | ⭐⭐⭐⭐ 優秀 | ✅ 推奨（コスト重視） |\n",
        "| **A100** | Ampere | 80GB | 高性能（FP16: 624 TFLOPS）、大規模モデル向け | **~30-40 CU** | ⭐⭐⭐ 良好 | ✅ 高性能が必要な場合 |\n",
        "| **H100** | Hopper | 80GB | 最新・最高性能（FP16: 1,513 TFLOPS）、Colabでは通常利用不可 | **~50-75 CU** | ⭐⭐ 低い | ⚠️ 過剰性能・利用困難 |\n",
        "| **TPU v6e-1** | TPU v6e | 32GB | 高性能（BF16: 918 TFLOPS）、TensorFlow/JAX向け | - | - | ❌ **非推奨**（PyTorch非対応） |\n",
        "| **TPU v5e-1** | TPU v5e | 16GB | コスト効率向上、TensorFlow/JAX向け | - | - | ❌ **非推奨**（PyTorch非対応） |\n",
        "\n",
        "**推奨順位**:\n",
        "1. **L4 GPU**: 性能とコストのバランスが最良。T4の後継で推奨。\n",
        "2. **T4 GPU**: コストが最も低く、確実に動作。時間に余裕がある場合に最適。\n",
        "3. **A100 GPU**: 高性能が必要で予算がある場合に検討。\n",
        "\n",
        "**注意事項**:\n",
        "- **TPUは非推奨**: YOLOv5はPyTorchベース（ultralytics）のため、TPUでは動作しない可能性が高い\n",
        "- ColabではGPUの割り当てがランダムな場合があります。希望するGPUが割り当てられない可能性があります\n",
        "- CU消費量はColab Pro（月額100ユニット付与）を基準としています\n",
        "- L4、A100、H100のCU消費量は推定値です（T4の実測値に基づく相対比較）\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 使用方法について\n",
        "\n",
        "このNotebookは`create_yolo_dataset.ipynb`の後に実行してください。\n",
        "\n",
        "- **前提**: `create_yolo_dataset.ipynb`で画像とラベルの1対1対応が完成していること\n",
        "- **入力**: `processed/{split}/images/` と `processed/{split}/labels/`\n",
        "- **出力**: 学習済みモデル（`.pt`ファイル）をGoogle Driveに保存\n",
        "- **結果**: ファインチューニング済みYOLOv5nモデル\n",
        "\n",
        "### 注意事項\n",
        "- **ローカルストレージを使用**: Google Driveへの直接アクセスは遅いため、一時的にローカルストレージ（/content/tmp/）を使用します\n",
        "- **GPU使用**: **最初からGPUランタイムで実行してください**（ランタイム → ランタイムのタイプを変更 → GPU）。CPUランタイムからGPUランタイムに変更すると、ローカルストレージのデータが消えます\n",
        "- **段階的fine-tuning**: このNotebookは段階2（Kaggleデータ）用です。段階3（自前データ）は別途実行してください\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone -b feature/onnx_recognizer https://github.com/masararutaru/last_assignment_progzissen.git\n",
        "# %cd last_assignment_progzissen\n",
        "# !git pull  # 毎回実行\n",
        "\n",
        "# 環境変数の設定\n",
        "import os\n",
        "os.environ[\"DATA_ROOT\"] = \"/content/drive/MyDrive/大学　講義/2年/後期/java_zissen/datasets/last_assignment\"\n",
        "os.environ[\"OUT_ROOT\"] = \"/content/drive/MyDrive/大学　講義/2年/後期/java_zissen/datasets/last_assignment\"\n",
        "\n",
        "print(\"環境変数設定完了\")\n",
        "print(f\"DATA_ROOT: {os.environ.get('DATA_ROOT')}\")\n",
        "print(f\"OUT_ROOT: {os.environ.get('OUT_ROOT')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## データセットをローカルストレージにコピー（高速化・train/val分割）\n",
        "\n",
        "Google Driveから直接読み込むと遅いため、ローカルストレージにコピーします。\n",
        "**初回のみ実行が必要です（数分かかります）。**\n",
        "\n",
        "**重要**: このセルでは、データを**train（80%）とval（20%）に自動分割**してコピーします。\n",
        "- 画像とラベルのペアを維持しながらランダムに分割\n",
        "- 再現性のため、ランダムシードを固定（`random_seed=42`）\n",
        "- YOLOv5が自動的にtrain/valを認識できる構造で保存\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# データセットをローカルストレージにコピー（train/val分割付き）\n",
        "import shutil\n",
        "import random\n",
        "import os\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 環境変数からパスを取得\n",
        "out_root = os.environ.get(\"OUT_ROOT\")\n",
        "if not out_root:\n",
        "    raise ValueError(\n",
        "        \"❌ エラー: OUT_ROOT環境変数が設定されていません。\\n\"\n",
        "        \"   セル3で環境変数を設定してください。\"\n",
        "    )\n",
        "\n",
        "split = 'train'  # ソースデータはtrainフォルダ\n",
        "\n",
        "# Google Driveのデータセットパス\n",
        "drive_data_dir = Path(out_root) / \"processed\" / split\n",
        "drive_images_dir = drive_data_dir / \"images\"\n",
        "drive_labels_dir = drive_data_dir / \"labels\"\n",
        "\n",
        "# ローカルストレージのパス（train/valに分割）\n",
        "local_dataset_dir = Path(\"/content/tmp/dataset\")\n",
        "local_train_images_dir = local_dataset_dir / \"train\" / \"images\"\n",
        "local_train_labels_dir = local_dataset_dir / \"train\" / \"labels\"\n",
        "local_val_images_dir = local_dataset_dir / \"val\" / \"images\"\n",
        "local_val_labels_dir = local_dataset_dir / \"val\" / \"labels\"\n",
        "\n",
        "# 分割比率\n",
        "train_ratio = 0.8  # 80% train, 20% val\n",
        "random_seed = 42  # 再現性のためのシード\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"データセットのローカルコピー（train/val分割）\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"ソース（Google Drive）: {drive_data_dir}\")\n",
        "print(f\"  画像: {drive_images_dir}\")\n",
        "print(f\"  ラベル: {drive_labels_dir}\")\n",
        "print(f\"出力先（ローカル）: {local_dataset_dir}\")\n",
        "print(f\"分割比率: {train_ratio*100:.0f}% train, {(1-train_ratio)*100:.0f}% val\")\n",
        "print(f\"ランダムシード: {random_seed}\")\n",
        "print()\n",
        "\n",
        "# 既にコピー済みか確認\n",
        "if local_train_images_dir.exists() and local_train_labels_dir.exists() and \\\n",
        "   local_val_images_dir.exists() and local_val_labels_dir.exists():\n",
        "    train_image_count = len(list(local_train_images_dir.glob('*.*')))\n",
        "    train_label_count = len(list(local_train_labels_dir.glob('*.txt')))\n",
        "    val_image_count = len(list(local_val_images_dir.glob('*.*')))\n",
        "    val_label_count = len(list(local_val_labels_dir.glob('*.txt')))\n",
        "    print(f\"✓ ローカルデータセットは既に存在します\")\n",
        "    print(f\"  Train: 画像 {train_image_count} 件, ラベル {train_label_count} 件\")\n",
        "    print(f\"  Val: 画像 {val_image_count} 件, ラベル {val_label_count} 件\")\n",
        "    print(f\"\\n再コピーする場合は、以下のコマンドを実行してください:\")\n",
        "    print(f\"  !rm -rf {local_dataset_dir}\")\n",
        "else:\n",
        "    # ソースの存在確認\n",
        "    if not drive_images_dir.exists():\n",
        "        raise FileNotFoundError(\n",
        "            f\"❌ エラー: 画像ディレクトリが見つかりません: {drive_images_dir}\\n\"\n",
        "            \"   先に create_yolo_dataset.ipynb を実行してください。\"\n",
        "        )\n",
        "    \n",
        "    if not drive_labels_dir.exists():\n",
        "        raise FileNotFoundError(\n",
        "            f\"❌ エラー: ラベルディレクトリが見つかりません: {drive_labels_dir}\\n\"\n",
        "            \"   先に preprocess_kaggle_data.ipynb を実行してください。\"\n",
        "        )\n",
        "    \n",
        "    # ファイルリストを取得（画像とラベルのペアを確認）\n",
        "    print(\"ファイルリストを取得中...\")\n",
        "    image_files = list(drive_images_dir.glob('*.*'))\n",
        "    label_files = list(drive_labels_dir.glob('*.txt'))\n",
        "    \n",
        "    # UUIDでペアリング\n",
        "    image_uuids = {f.stem: f for f in image_files}\n",
        "    label_uuids = {f.stem: f for f in label_files}\n",
        "    matched_uuids = sorted(set(image_uuids.keys()) & set(label_uuids.keys()))\n",
        "    \n",
        "    print(f\"\\n見つかったファイル:\")\n",
        "    print(f\"  画像ファイル: {len(image_files)} 件\")\n",
        "    print(f\"  ラベルファイル: {len(label_files)} 件\")\n",
        "    print(f\"  対応しているペア数: {len(matched_uuids)} 件\")\n",
        "    \n",
        "    if len(matched_uuids) == 0:\n",
        "        raise ValueError(\"❌ エラー: 対応している画像とラベルのペアが見つかりません\")\n",
        "    \n",
        "    # ランダムにシャッフル（シード固定で再現性を確保）\n",
        "    random.seed(random_seed)\n",
        "    shuffled_uuids = matched_uuids.copy()\n",
        "    random.shuffle(shuffled_uuids)\n",
        "    \n",
        "    # train/valに分割\n",
        "    split_idx = int(len(shuffled_uuids) * train_ratio)\n",
        "    train_uuids = shuffled_uuids[:split_idx]\n",
        "    val_uuids = shuffled_uuids[split_idx:]\n",
        "    \n",
        "    print(f\"\\n分割結果:\")\n",
        "    print(f\"  Train: {len(train_uuids)} 件 ({len(train_uuids)/len(shuffled_uuids)*100:.1f}%)\")\n",
        "    print(f\"  Val: {len(val_uuids)} 件 ({len(val_uuids)/len(shuffled_uuids)*100:.1f}%)\")\n",
        "    print()\n",
        "    \n",
        "    # ディレクトリ作成\n",
        "    local_train_images_dir.mkdir(parents=True, exist_ok=True)\n",
        "    local_train_labels_dir.mkdir(parents=True, exist_ok=True)\n",
        "    local_val_images_dir.mkdir(parents=True, exist_ok=True)\n",
        "    local_val_labels_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Trainデータをコピー\n",
        "    print(\"=\" * 80)\n",
        "    print(\"Trainデータをコピー中...\")\n",
        "    print(\"=\" * 80)\n",
        "    copied_train_images = 0\n",
        "    copied_train_labels = 0\n",
        "    \n",
        "    for uuid in tqdm(train_uuids, desc=\"Trainコピー\", unit=\"ペア\"):\n",
        "        # 画像をコピー\n",
        "        src_img = image_uuids[uuid]\n",
        "        dst_img = local_train_images_dir / src_img.name\n",
        "        if not dst_img.exists():\n",
        "            shutil.copy2(src_img, dst_img)\n",
        "            copied_train_images += 1\n",
        "        \n",
        "        # ラベルをコピー\n",
        "        src_label = label_uuids[uuid]\n",
        "        dst_label = local_train_labels_dir / src_label.name\n",
        "        if not dst_label.exists():\n",
        "            shutil.copy2(src_label, dst_label)\n",
        "            copied_train_labels += 1\n",
        "    \n",
        "    print(f\"Trainコピー完了: 画像 {copied_train_images} 件, ラベル {copied_train_labels} 件\")\n",
        "    \n",
        "    # Valデータをコピー\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"Valデータをコピー中...\")\n",
        "    print(\"=\" * 80)\n",
        "    copied_val_images = 0\n",
        "    copied_val_labels = 0\n",
        "    \n",
        "    for uuid in tqdm(val_uuids, desc=\"Valコピー\", unit=\"ペア\"):\n",
        "        # 画像をコピー\n",
        "        src_img = image_uuids[uuid]\n",
        "        dst_img = local_val_images_dir / src_img.name\n",
        "        if not dst_img.exists():\n",
        "            shutil.copy2(src_img, dst_img)\n",
        "            copied_val_images += 1\n",
        "        \n",
        "        # ラベルをコピー\n",
        "        src_label = label_uuids[uuid]\n",
        "        dst_label = local_val_labels_dir / src_label.name\n",
        "        if not dst_label.exists():\n",
        "            shutil.copy2(src_label, dst_label)\n",
        "            copied_val_labels += 1\n",
        "    \n",
        "    print(f\"Valコピー完了: 画像 {copied_val_images} 件, ラベル {copied_val_labels} 件\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"✓ コピー完了\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"Train: {len(train_uuids)} ペア\")\n",
        "    print(f\"Val: {len(val_uuids)} ペア\")\n",
        "    print(f\"\\nローカルパス: {local_dataset_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# データセットの確認\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "\n",
        "# パスを追加（リポジトリのpython/dataディレクトリ）\n",
        "repo_path = Path('/content/last_assignment_progzissen')\n",
        "sys.path.insert(0, str(repo_path / 'python' / 'data'))\n",
        "\n",
        "from config import CLASSES\n",
        "\n",
        "# ローカルデータセットのパス（train/valに分割済み）\n",
        "local_dataset_dir = Path(\"/content/tmp/dataset\")\n",
        "local_train_images_dir = local_dataset_dir / \"train\" / \"images\"\n",
        "local_train_labels_dir = local_dataset_dir / \"train\" / \"labels\"\n",
        "local_val_images_dir = local_dataset_dir / \"val\" / \"images\"\n",
        "local_val_labels_dir = local_dataset_dir / \"val\" / \"labels\"\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"データセット確認\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Trainデータの確認\n",
        "print(\"\\nTrainデータを確認中...\")\n",
        "train_image_files = list(local_train_images_dir.glob('*.*'))\n",
        "train_label_files = list(local_train_labels_dir.glob('*.txt'))\n",
        "\n",
        "print(f\"Train - 画像ファイル数: {len(train_image_files)} 件\")\n",
        "print(f\"Train - ラベルファイル数: {len(train_label_files)} 件\")\n",
        "\n",
        "# Valデータの確認\n",
        "print(\"\\nValデータを確認中...\")\n",
        "val_image_files = list(local_val_images_dir.glob('*.*'))\n",
        "val_label_files = list(local_val_labels_dir.glob('*.txt'))\n",
        "\n",
        "print(f\"Val - 画像ファイル数: {len(val_image_files)} 件\")\n",
        "print(f\"Val - ラベルファイル数: {len(val_label_files)} 件\")\n",
        "\n",
        "# 1対1対応の確認（Train）\n",
        "train_image_uuids = {f.stem for f in train_image_files}\n",
        "train_label_uuids = {f.stem for f in train_label_files}\n",
        "train_matched = train_image_uuids & train_label_uuids\n",
        "\n",
        "print(f\"\\nTrain - 1対1対応:\")\n",
        "print(f\"  画像ファイル: {len(train_image_uuids)} 件\")\n",
        "print(f\"  ラベルファイル: {len(train_label_uuids)} 件\")\n",
        "print(f\"  対応しているペア数: {len(train_matched)} 件\")\n",
        "\n",
        "# 1対1対応の確認（Val）\n",
        "val_image_uuids = {f.stem for f in val_image_files}\n",
        "val_label_uuids = {f.stem for f in val_label_files}\n",
        "val_matched = val_image_uuids & val_label_uuids\n",
        "\n",
        "print(f\"\\nVal - 1対1対応:\")\n",
        "print(f\"  画像ファイル: {len(val_image_uuids)} 件\")\n",
        "print(f\"  ラベルファイル: {len(val_label_uuids)} 件\")\n",
        "print(f\"  対応しているペア数: {len(val_matched)} 件\")\n",
        "\n",
        "if len(train_matched) != len(train_image_uuids) or len(train_matched) != len(train_label_uuids):\n",
        "    print(f\"\\n⚠️  警告: Trainデータで一部のファイルが対応していません\")\n",
        "if len(val_matched) != len(val_image_uuids) or len(val_matched) != len(val_label_uuids):\n",
        "    print(f\"\\n⚠️  警告: Valデータで一部のファイルが対応していません\")\n",
        "\n",
        "# クラス別統計（Train）\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Trainデータ - クラス別統計を集計中...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "train_class_stats = defaultdict(int)\n",
        "train_total_instances = 0\n",
        "\n",
        "for label_file in tqdm(train_label_files, desc=\"Trainラベル解析\", unit=\"ファイル\"):\n",
        "    with open(label_file, 'r') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) >= 5:\n",
        "                class_id = int(parts[0])\n",
        "                if 0 <= class_id < len(CLASSES):\n",
        "                    train_class_stats[CLASSES[class_id]] += 1\n",
        "                    train_total_instances += 1\n",
        "\n",
        "print(f\"\\nTrain - クラス別インスタンス数:\")\n",
        "print(\"-\" * 60)\n",
        "for cls in CLASSES:\n",
        "    count = train_class_stats[cls]\n",
        "    print(f\"  {cls:>3}: {count:>8} インスタンス\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"Train - 総インスタンス数: {train_total_instances}\")\n",
        "\n",
        "# クラス別統計（Val）\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Valデータ - クラス別統計を集計中...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "val_class_stats = defaultdict(int)\n",
        "val_total_instances = 0\n",
        "\n",
        "for label_file in tqdm(val_label_files, desc=\"Valラベル解析\", unit=\"ファイル\"):\n",
        "    with open(label_file, 'r') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) >= 5:\n",
        "                class_id = int(parts[0])\n",
        "                if 0 <= class_id < len(CLASSES):\n",
        "                    val_class_stats[CLASSES[class_id]] += 1\n",
        "                    val_total_instances += 1\n",
        "\n",
        "print(f\"\\nVal - クラス別インスタンス数:\")\n",
        "print(\"-\" * 60)\n",
        "for cls in CLASSES:\n",
        "    count = val_class_stats[cls]\n",
        "    print(f\"  {cls:>3}: {count:>8} インスタンス\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"Val - 総インスタンス数: {val_total_instances}\")\n",
        "\n",
        "if train_total_instances == 0:\n",
        "    print(\"\\n⚠️  警告: Trainデータにインスタンスが見つかりませんでした\")\n",
        "if val_total_instances == 0:\n",
        "    print(\"\\n⚠️  警告: Valデータにインスタンスが見つかりませんでした\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ultralyticsのインストール（必要に応じて）\n",
        "!pip install ultralytics -q\n",
        "\n",
        "from ultralytics import YOLO\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "# パスを追加（CLASSESをインポートするため）\n",
        "repo_path = Path('/content/last_assignment_progzissen')\n",
        "sys.path.insert(0, str(repo_path / 'python' / 'data'))\n",
        "\n",
        "from config import CLASSES\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"事前学習済みモデルの準備\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# YOLOv5nモデルを読み込み（初回実行時に自動ダウンロード）\n",
        "print(\"\\nYOLOv5nモデルを読み込み中...\")\n",
        "print(\"（初回実行時は自動ダウンロードされます。約4.5MB、数秒かかります）\")\n",
        "\n",
        "model = YOLO('yolov5n.pt')\n",
        "\n",
        "print(\"\\n✓ モデル読み込み完了\")\n",
        "print(f\"  モデル名: YOLOv5n\")\n",
        "print(f\"  クラス数: {len(CLASSES)} クラス\")\n",
        "print(f\"  クラス: {', '.join(CLASSES)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 学習設定\n",
        "\n",
        "学習パラメータを設定します。段階2（Kaggleデータ）用の設定です。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOLOデータセット設定ファイル（data.yaml）の作成\n",
        "!pip install pyyaml -q\n",
        "\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "# パスを追加（CLASSESをインポートするため）\n",
        "repo_path = Path('/content/last_assignment_progzissen')\n",
        "sys.path.insert(0, str(repo_path / 'python' / 'data'))\n",
        "\n",
        "from config import CLASSES\n",
        "\n",
        "data_yaml_path = Path(\"/content/tmp/dataset/data.yaml\")\n",
        "\n",
        "data_config = {\n",
        "    'path': str(Path(\"/content/tmp/dataset\").absolute()),\n",
        "    'train': 'train/images',\n",
        "    'val': 'val/images',\n",
        "    'nc': len(CLASSES),\n",
        "    'names': CLASSES\n",
        "}\n",
        "\n",
        "with open(data_yaml_path, 'w') as f:\n",
        "    yaml.dump(data_config, f, default_flow_style=False)\n",
        "\n",
        "# ファイルの存在確認\n",
        "if not data_yaml_path.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"❌ エラー: データセット設定ファイルの作成に失敗しました: {data_yaml_path}\"\n",
        "    )\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"YOLOデータセット設定ファイル作成\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"設定ファイル: {data_yaml_path}\")\n",
        "print(f\"\\n内容:\")\n",
        "print(yaml.dump(data_config, default_flow_style=False))\n",
        "\n",
        "# data_pathをyamlファイルに変更\n",
        "data_path = str(data_yaml_path)\n",
        "print(f\"\\n✓ データセットパスを更新: {data_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 学習設定\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "# データセット設定ファイルの確認\n",
        "if 'data_path' not in globals():\n",
        "    raise ValueError(\n",
        "        \"❌ エラー: データセット設定ファイルが作成されていません。\\n\"\n",
        "        \"   先にセル12（YOLOデータセット設定ファイル作成）を実行してください。\"\n",
        "    )\n",
        "\n",
        "# パスを追加（CLASSESをインポートするため）\n",
        "repo_path = Path('/content/last_assignment_progzissen')\n",
        "sys.path.insert(0, str(repo_path / 'python' / 'data'))\n",
        "\n",
        "from config import CLASSES\n",
        "\n",
        "# split変数の定義（セル6で定義されているが、念のため再定義）\n",
        "split = 'train'  # ソースデータはtrainフォルダ\n",
        "\n",
        "# データセットパス（セル12でdata.yamlに設定済み）\n",
        "# data_pathはセル12で設定されているので、ここでは再設定しない\n",
        "\n",
        "# 学習パラメータ\n",
        "epochs = 50  # エポック数\n",
        "batch_size = 16  # バッチサイズ（GPUメモリに応じて調整）\n",
        "# GPUメモリ容量別の推奨バッチサイズ目安:\n",
        "#   - 8GB  (例: RTX 3060, RTX 3070): batch_size = 8 程度\n",
        "#   - 12GB (例: RTX 3060 12GB): batch_size = 12 程度\n",
        "#   - 16GB (例: P100, T4): batch_size = 16 程度（現在の設定）\n",
        "#   - 24GB (例: RTX 3090, RTX 4090, A100): batch_size = 24 程度\n",
        "img_size = 640  # 画像サイズ\n",
        "device = 0  # GPU使用（0: GPU, cpu: CPU）\n",
        "\n",
        "# 出力先（ローカルストレージ）\n",
        "project_path = \"/content/tmp/runs\"\n",
        "run_name = f\"yolov5n_kaggle_{split}\"\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"学習設定\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"データセット: {data_path}\")\n",
        "print(f\"エポック数: {epochs}\")\n",
        "print(f\"バッチサイズ: {batch_size}\")\n",
        "print(f\"画像サイズ: {img_size}\")\n",
        "print(f\"デバイス: {'GPU' if device == 0 else 'CPU'}\")\n",
        "print(f\"出力先: {project_path}/{run_name}\")\n",
        "print(f\"\\nクラス数: {len(CLASSES)} クラス\")\n",
        "print(f\"クラス: {', '.join(CLASSES)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 学習の実行\n",
        "\n",
        "**注意**: このセルは長時間かかります（数時間）。GPUランタイムを使用してください。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 学習の実行\n",
        "print(\"=\" * 80)\n",
        "print(\"学習開始\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"開始時刻: {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print()\n",
        "\n",
        "# 学習実行\n",
        "results = model.train(\n",
        "    data=data_path,\n",
        "    epochs=epochs,\n",
        "    batch=batch_size,\n",
        "    imgsz=img_size,\n",
        "    device=device,\n",
        "    project=project_path,\n",
        "    name=run_name,\n",
        "    save=True,\n",
        "    save_period=10,  # 10エポックごとに保存\n",
        "    val=True,  # 検証データで評価\n",
        "    plots=True,  # 学習曲線をプロット\n",
        "    verbose=True,  # 詳細ログ\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"学習完了\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"終了時刻: {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 学習結果の確認\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 学習結果の確認\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "# 学習設定の確認\n",
        "if 'project_path' not in globals() or 'run_name' not in globals():\n",
        "    raise ValueError(\n",
        "        \"❌ エラー: 学習設定が完了していません。\\n\"\n",
        "        \"   先にセル13（学習設定）を実行してください。\"\n",
        "    )\n",
        "\n",
        "results_dir = Path(project_path) / run_name\n",
        "weights_dir = results_dir / \"weights\"\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"学習結果\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"結果ディレクトリ: {results_dir}\")\n",
        "\n",
        "# 重みファイルの確認\n",
        "if weights_dir.exists():\n",
        "    weight_files = list(weights_dir.glob('*.pt'))\n",
        "    print(f\"\\n重みファイル数: {len(weight_files)} 件\")\n",
        "    \n",
        "    for wf in sorted(weight_files):\n",
        "        size_mb = wf.stat().st_size / (1024 * 1024)\n",
        "        print(f\"  {wf.name}: {size_mb:.2f} MB\")\n",
        "    \n",
        "    # 最良モデル\n",
        "    best_model = weights_dir / \"best.pt\"\n",
        "    if best_model.exists():\n",
        "        print(f\"\\n✓ 最良モデル: {best_model.name}\")\n",
        "        print(f\"  サイズ: {best_model.stat().st_size / (1024 * 1024):.2f} MB\")\n",
        "    \n",
        "    # 最終モデル\n",
        "    last_model = weights_dir / \"last.pt\"\n",
        "    if last_model.exists():\n",
        "        print(f\"✓ 最終モデル: {last_model.name}\")\n",
        "        print(f\"  サイズ: {last_model.stat().st_size / (1024 * 1024):.2f} MB\")\n",
        "else:\n",
        "    print(\"\\n⚠️  重みファイルが見つかりません\")\n",
        "\n",
        "# 学習曲線の確認\n",
        "results_csv = results_dir / \"results.csv\"\n",
        "if results_csv.exists():\n",
        "    print(f\"\\n学習曲線データ: {results_csv}\")\n",
        "    print(\"  （results.csvをダウンロードしてExcel等で確認できます）\")\n",
        "\n",
        "# プロット画像の確認\n",
        "plot_files = list(results_dir.glob(\"*.png\"))\n",
        "if len(plot_files) > 0:\n",
        "    print(f\"\\nプロット画像数: {len(plot_files)} 件\")\n",
        "    for pf in plot_files:\n",
        "        print(f\"  {pf.name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 学習結果をGoogle Driveに保存\n",
        "\n",
        "学習済みモデル、学習曲線、プロット画像を全てGoogle Driveに保存して、次回以降も使用できるようにします。\n",
        "\n",
        "**保存内容**:\n",
        "- 最良モデル（best.pt）\n",
        "- 最終モデル（last.pt、存在する場合）\n",
        "- 学習曲線データ（results.csv）\n",
        "- プロット画像（*.png）\n",
        "\n",
        "**フォルダ構成**:\n",
        "学習設定（データセット、エポック数、バッチサイズ）を含むフォルダ名で保存します。\n",
        "例: `yolov5n_kaggle_train_epochs50_batch16_20240101_120000`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 学習結果をGoogle Driveに保存\n",
        "import shutil\n",
        "import os\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 環境変数からパスを取得\n",
        "out_root = os.environ.get(\"OUT_ROOT\")\n",
        "if not out_root:\n",
        "    raise ValueError(\n",
        "        \"❌ エラー: OUT_ROOT環境変数が設定されていません。\\n\"\n",
        "        \"   セル4で環境変数を設定してください。\"\n",
        "    )\n",
        "\n",
        "# 学習設定の確認\n",
        "if 'project_path' not in globals() or 'run_name' not in globals() or \\\n",
        "   'split' not in globals() or 'epochs' not in globals() or 'batch_size' not in globals():\n",
        "    raise ValueError(\n",
        "        \"❌ エラー: 学習設定が完了していません。\\n\"\n",
        "        \"   先にセル13（学習設定）を実行してください。\"\n",
        "    )\n",
        "\n",
        "# ローカルの結果ディレクトリ\n",
        "local_results_dir = Path(project_path) / run_name\n",
        "local_weights_dir = local_results_dir / \"weights\"\n",
        "\n",
        "if not local_results_dir.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"❌ エラー: 学習結果ディレクトリが見つかりません: {local_results_dir}\\n\"\n",
        "        \"   先に学習を実行してください。\"\n",
        "    )\n",
        "\n",
        "# フォルダ名を作成（学習設定を含む）\n",
        "# 形式: yolov5n_kaggle_{split}_epochs{epochs}_batch{batch_size}_{timestamp}\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "folder_name = f\"yolov5n_kaggle_{split}_epochs{epochs}_batch{batch_size}_{timestamp}\"\n",
        "\n",
        "# Google Driveの保存先（weightsディレクトリ配下に学習結果フォルダを作成）\n",
        "drive_weights_dir = Path(out_root) / \"weights\"\n",
        "drive_results_dir = drive_weights_dir / folder_name\n",
        "drive_results_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"学習結果をGoogle Driveに保存\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"ソース: {local_results_dir}\")\n",
        "print(f\"保存先: {drive_results_dir}\")\n",
        "print(f\"フォルダ名: {folder_name}\")\n",
        "print()\n",
        "\n",
        "# コピーするファイルのリスト\n",
        "files_to_copy = []\n",
        "\n",
        "# 1. 最良モデル（best.pt）\n",
        "local_best_model = local_weights_dir / \"best.pt\"\n",
        "if local_best_model.exists():\n",
        "    files_to_copy.append((\"最良モデル\", local_best_model, drive_results_dir / \"best.pt\"))\n",
        "else:\n",
        "    print(\"⚠️  最良モデル（best.pt）が見つかりません\")\n",
        "\n",
        "# 2. 最終モデル（last.pt）\n",
        "local_last_model = local_weights_dir / \"last.pt\"\n",
        "if local_last_model.exists():\n",
        "    files_to_copy.append((\"最終モデル\", local_last_model, drive_results_dir / \"last.pt\"))\n",
        "\n",
        "# 3. 学習曲線データ（results.csv）\n",
        "local_results_csv = local_results_dir / \"results.csv\"\n",
        "if local_results_csv.exists():\n",
        "    files_to_copy.append((\"学習曲線データ\", local_results_csv, drive_results_dir / \"results.csv\"))\n",
        "else:\n",
        "    print(\"⚠️  学習曲線データ（results.csv）が見つかりません\")\n",
        "\n",
        "# 4. プロット画像（*.png）\n",
        "plot_files = list(local_results_dir.glob(\"*.png\"))\n",
        "for plot_file in plot_files:\n",
        "    files_to_copy.append((f\"プロット画像: {plot_file.name}\", plot_file, drive_results_dir / plot_file.name))\n",
        "\n",
        "if len(plot_files) == 0:\n",
        "    print(\"⚠️  プロット画像（*.png）が見つかりません\")\n",
        "\n",
        "print(f\"\\n保存するファイル数: {len(files_to_copy)} 件\")\n",
        "print()\n",
        "\n",
        "# ファイルをコピー\n",
        "copied_count = 0\n",
        "total_size_mb = 0\n",
        "\n",
        "for desc, src_file, dst_file in files_to_copy:\n",
        "    if not src_file.exists():\n",
        "        print(f\"⚠️  スキップ: {desc}（ファイルが見つかりません）\")\n",
        "        continue\n",
        "    \n",
        "    file_size = src_file.stat().st_size\n",
        "    size_mb = file_size / (1024 * 1024)\n",
        "    total_size_mb += size_mb\n",
        "    \n",
        "    print(f\"コピー中: {desc}\")\n",
        "    print(f\"  サイズ: {size_mb:.2f} MB\")\n",
        "    \n",
        "    # 大きなファイルの場合は進捗表示付きでコピー\n",
        "    if file_size > 10 * 1024 * 1024:  # 10MB以上の場合\n",
        "        chunk_size = 1024 * 1024  # 1MB\n",
        "        with open(src_file, 'rb') as src, open(dst_file, 'wb') as dst:\n",
        "            with tqdm(total=file_size, unit='B', unit_scale=True, desc=\"  \", leave=False) as pbar:\n",
        "                while True:\n",
        "                    chunk = src.read(chunk_size)\n",
        "                    if not chunk:\n",
        "                        break\n",
        "                    dst.write(chunk)\n",
        "                    pbar.update(len(chunk))\n",
        "    else:\n",
        "        # 小さいファイルは通常のコピー\n",
        "        shutil.copy2(src_file, dst_file)\n",
        "    \n",
        "    copied_count += 1\n",
        "    print(f\"  ✓ 完了\\n\")\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"✓ 保存完了\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"保存したファイル数: {copied_count} 件\")\n",
        "print(f\"合計サイズ: {total_size_mb:.2f} MB\")\n",
        "print(f\"\\n保存先: {drive_results_dir}\")\n",
        "print(f\"\\n次回以降は以下のパスから読み込めます:\")\n",
        "print(f\"  最良モデル: {drive_results_dir / 'best.pt'}\")\n",
        "if local_results_csv.exists():\n",
        "    print(f\"  学習曲線: {drive_results_dir / 'results.csv'}\")\n",
        "if len(plot_files) > 0:\n",
        "    print(f\"  プロット画像: {drive_results_dir}/*.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
