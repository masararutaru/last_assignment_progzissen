{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# YOLOv5モデルのファインチューニング\n",
        "\n",
        "このNotebookでは、COCO事前学習済みYOLOv5nモデルをKaggle OCRデータセットでファインチューニングします。\n",
        "\n",
        "**高速化のため、ローカルストレージ（/content/tmp/）を使用します。**\n",
        "\n",
        "## 処理の流れ\n",
        "1. Google Driveのマウント\n",
        "2. Gitリポジトリのクローン/更新\n",
        "3. 環境変数の設定\n",
        "4. データセットをローカルストレージにコピー（高速化）\n",
        "5. データセットの確認\n",
        "6. 事前学習済みモデルの準備\n",
        "7. 学習設定\n",
        "8. 学習の実行\n",
        "9. 学習結果の確認\n",
        "10. 最良モデルをGoogle Driveに保存\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 使用方法について\n",
        "\n",
        "このNotebookは`create_yolo_dataset.ipynb`の後に実行してください。\n",
        "\n",
        "- **前提**: `create_yolo_dataset.ipynb`で画像とラベルの1対1対応が完成していること\n",
        "- **入力**: `processed/{split}/images/` と `processed/{split}/labels/`\n",
        "- **出力**: 学習済みモデル（`.pt`ファイル）をGoogle Driveに保存\n",
        "- **結果**: ファインチューニング済みYOLOv5nモデル\n",
        "\n",
        "### 注意事項\n",
        "- **ローカルストレージを使用**: Google Driveへの直接アクセスは遅いため、一時的にローカルストレージ（/content/tmp/）を使用します\n",
        "- **GPU使用**: ColabのGPUランタイムを使用してください（ランタイム → ランタイムのタイプを変更 → GPU）\n",
        "- **段階的fine-tuning**: このNotebookは段階2（Kaggleデータ）用です。段階3（自前データ）は別途実行してください\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone -b feature/onnx_recognizer https://github.com/masararutaru/last_assignment_progzissen.git\n",
        "# %cd last_assignment_progzissen\n",
        "# !git pull  # 毎回実行\n",
        "\n",
        "# 環境変数の設定\n",
        "import os\n",
        "os.environ[\"DATA_ROOT\"] = \"/content/drive/MyDrive/大学　講義/2年/後期/java_zissen/datasets/last_assignment\"\n",
        "os.environ[\"OUT_ROOT\"] = \"/content/drive/MyDrive/大学　講義/2年/後期/java_zissen/datasets/last_assignment\"\n",
        "\n",
        "print(\"環境変数設定完了\")\n",
        "print(f\"DATA_ROOT: {os.environ.get('DATA_ROOT')}\")\n",
        "print(f\"OUT_ROOT: {os.environ.get('OUT_ROOT')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## データセットをローカルストレージにコピー（高速化）\n",
        "\n",
        "Google Driveから直接読み込むと遅いため、ローカルストレージにコピーします。\n",
        "**初回のみ実行が必要です（数分かかります）。**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# データセットをローカルストレージにコピー\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 環境変数からパスを取得\n",
        "out_root = os.environ.get(\"OUT_ROOT\")\n",
        "if not out_root:\n",
        "    raise ValueError(\n",
        "        \"❌ エラー: OUT_ROOT環境変数が設定されていません。\\n\"\n",
        "        \"   セル3で環境変数を設定してください。\"\n",
        "    )\n",
        "\n",
        "split = 'train'  # 'train', 'val', 'test' を変更可能\n",
        "\n",
        "# Google Driveのデータセットパス\n",
        "drive_data_dir = Path(out_root) / \"processed\" / split\n",
        "drive_images_dir = drive_data_dir / \"images\"\n",
        "drive_labels_dir = drive_data_dir / \"labels\"\n",
        "\n",
        "# ローカルストレージのパス\n",
        "local_data_dir = Path(\"/content/tmp/dataset\") / split\n",
        "local_images_dir = local_data_dir / \"images\"\n",
        "local_labels_dir = local_data_dir / \"labels\"\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"データセットのローカルコピー\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"ソース（Google Drive）: {drive_data_dir}\")\n",
        "print(f\"  画像: {drive_images_dir}\")\n",
        "print(f\"  ラベル: {drive_labels_dir}\")\n",
        "print(f\"出力先（ローカル）: {local_data_dir}\")\n",
        "print()\n",
        "\n",
        "# 既にコピー済みか確認\n",
        "if local_images_dir.exists() and local_labels_dir.exists():\n",
        "    image_count = len(list(local_images_dir.glob('*.*')))\n",
        "    label_count = len(list(local_labels_dir.glob('*.txt')))\n",
        "    print(f\"✓ ローカルデータセットは既に存在します\")\n",
        "    print(f\"  画像ファイル数: {image_count} 件\")\n",
        "    print(f\"  ラベルファイル数: {label_count} 件\")\n",
        "    print(f\"\\n再コピーする場合は、以下のコマンドを実行してください:\")\n",
        "    print(f\"  !rm -rf {local_data_dir}\")\n",
        "else:\n",
        "    # ソースの存在確認\n",
        "    if not drive_images_dir.exists():\n",
        "        raise FileNotFoundError(\n",
        "            f\"❌ エラー: 画像ディレクトリが見つかりません: {drive_images_dir}\\n\"\n",
        "            \"   先に create_yolo_dataset.ipynb を実行してください。\"\n",
        "        )\n",
        "    \n",
        "    if not drive_labels_dir.exists():\n",
        "        raise FileNotFoundError(\n",
        "            f\"❌ エラー: ラベルディレクトリが見つかりません: {drive_labels_dir}\\n\"\n",
        "            \"   先に preprocess_kaggle_data.ipynb を実行してください。\"\n",
        "        )\n",
        "    \n",
        "    # ファイルリストを取得\n",
        "    print(\"ファイルリストを取得中...\")\n",
        "    image_files = list(drive_images_dir.glob('*.*'))\n",
        "    label_files = list(drive_labels_dir.glob('*.txt'))\n",
        "    \n",
        "    print(f\"\\n見つかったファイル:\")\n",
        "    print(f\"  画像ファイル: {len(image_files)} 件\")\n",
        "    print(f\"  ラベルファイル: {len(label_files)} 件\")\n",
        "    print()\n",
        "    \n",
        "    # ディレクトリ作成\n",
        "    local_images_dir.mkdir(parents=True, exist_ok=True)\n",
        "    local_labels_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # 画像ファイルをコピー（進捗表示付き）\n",
        "    print(\"=\" * 80)\n",
        "    print(\"画像ファイルをコピー中...\")\n",
        "    print(\"=\" * 80)\n",
        "    copied_images = 0\n",
        "    skipped_images = 0\n",
        "    \n",
        "    for img_file in tqdm(image_files, desc=\"画像コピー\", unit=\"ファイル\"):\n",
        "        target_path = local_images_dir / img_file.name\n",
        "        if target_path.exists():\n",
        "            skipped_images += 1\n",
        "            continue\n",
        "        try:\n",
        "            shutil.copy2(img_file, target_path)\n",
        "            copied_images += 1\n",
        "        except Exception as e:\n",
        "            print(f\"\\n⚠️  エラー: {img_file.name} のコピーに失敗: {e}\")\n",
        "    \n",
        "    print(f\"\\n画像コピー完了: コピー {copied_images} 件, スキップ {skipped_images} 件\")\n",
        "    \n",
        "    # ラベルファイルをコピー（進捗表示付き）\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"ラベルファイルをコピー中...\")\n",
        "    print(\"=\" * 80)\n",
        "    copied_labels = 0\n",
        "    skipped_labels = 0\n",
        "    \n",
        "    for label_file in tqdm(label_files, desc=\"ラベルコピー\", unit=\"ファイル\"):\n",
        "        target_path = local_labels_dir / label_file.name\n",
        "        if target_path.exists():\n",
        "            skipped_labels += 1\n",
        "            continue\n",
        "        try:\n",
        "            shutil.copy2(label_file, target_path)\n",
        "            copied_labels += 1\n",
        "        except Exception as e:\n",
        "            print(f\"\\n⚠️  エラー: {label_file.name} のコピーに失敗: {e}\")\n",
        "    \n",
        "    print(f\"\\nラベルコピー完了: コピー {copied_labels} 件, スキップ {skipped_labels} 件\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"✓ コピー完了\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"画像ファイル数: {len(image_files)} 件\")\n",
        "    print(f\"ラベルファイル数: {len(label_files)} 件\")\n",
        "    print(f\"\\nローカルパス: {local_data_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# データセットの確認\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "# パスを追加（リポジトリのpython/dataディレクトリ）\n",
        "repo_path = Path('/content/last_assignment_progzissen')\n",
        "sys.path.insert(0, str(repo_path / 'python' / 'data'))\n",
        "\n",
        "from config import CLASSES\n",
        "\n",
        "# ローカルデータセットのパス\n",
        "local_data_dir = Path(\"/content/tmp/dataset\") / split\n",
        "local_images_dir = local_data_dir / \"images\"\n",
        "local_labels_dir = local_data_dir / \"labels\"\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"データセット確認\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# ファイル数の確認\n",
        "print(\"\\nファイル数を確認中...\")\n",
        "image_files = list(local_images_dir.glob('*.*'))\n",
        "label_files = list(local_labels_dir.glob('*.txt'))\n",
        "\n",
        "print(f\"\\n画像ファイル数: {len(image_files)} 件\")\n",
        "print(f\"ラベルファイル数: {len(label_files)} 件\")\n",
        "\n",
        "# 1対1対応の確認\n",
        "image_uuids = {f.stem for f in image_files}\n",
        "label_uuids = {f.stem for f in label_files}\n",
        "matched = image_uuids & label_uuids\n",
        "\n",
        "print(f\"\\n1対1対応:\")\n",
        "print(f\"  画像ファイル: {len(image_uuids)} 件\")\n",
        "print(f\"  ラベルファイル: {len(label_uuids)} 件\")\n",
        "print(f\"  対応しているペア数: {len(matched)} 件\")\n",
        "\n",
        "if len(matched) != len(image_uuids) or len(matched) != len(label_uuids):\n",
        "    print(f\"\\n⚠️  警告: 一部のファイルが対応していません\")\n",
        "    if len(image_uuids) != len(label_uuids):\n",
        "        print(f\"  画像のみ: {len(image_uuids - label_uuids)} 件\")\n",
        "        print(f\"  ラベルのみ: {len(label_uuids - image_uuids)} 件\")\n",
        "\n",
        "# クラス別統計（進捗表示付き）\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"クラス別統計を集計中...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "class_stats = defaultdict(int)\n",
        "total_instances = 0\n",
        "\n",
        "for label_file in tqdm(label_files, desc=\"ラベル解析\", unit=\"ファイル\"):\n",
        "    with open(label_file, 'r') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) >= 5:\n",
        "                class_id = int(parts[0])\n",
        "                if 0 <= class_id < len(CLASSES):\n",
        "                    class_stats[CLASSES[class_id]] += 1\n",
        "                    total_instances += 1\n",
        "\n",
        "print(f\"\\nクラス別インスタンス数:\")\n",
        "print(\"-\" * 60)\n",
        "for cls in CLASSES:\n",
        "    count = class_stats[cls]\n",
        "    print(f\"  {cls:>3}: {count:>8} インスタンス\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"総インスタンス数: {total_instances}\")\n",
        "\n",
        "if total_instances == 0:\n",
        "    print(\"\\n⚠️  警告: インスタンスが見つかりませんでした\")\n",
        "    print(\"   データセットを確認してください。\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ultralyticsのインストール（必要に応じて）\n",
        "!pip install ultralytics -q\n",
        "\n",
        "from ultralytics import YOLO\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"事前学習済みモデルの準備\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# YOLOv5nモデルを読み込み（初回実行時に自動ダウンロード）\n",
        "print(\"\\nYOLOv5nモデルを読み込み中...\")\n",
        "print(\"（初回実行時は自動ダウンロードされます。約4.5MB、数秒かかります）\")\n",
        "\n",
        "model = YOLO('yolov5n.pt')\n",
        "\n",
        "print(\"\\n✓ モデル読み込み完了\")\n",
        "print(f\"  モデル名: YOLOv5n\")\n",
        "print(f\"  クラス数: {len(CLASSES)} クラス\")\n",
        "print(f\"  クラス: {', '.join(CLASSES)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 学習設定\n",
        "\n",
        "学習パラメータを設定します。段階2（Kaggleデータ）用の設定です。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 学習設定\n",
        "from pathlib import Path\n",
        "\n",
        "# データセットパス（ローカルストレージ）\n",
        "data_path = str(Path(\"/content/tmp/dataset\") / split)\n",
        "\n",
        "# 学習パラメータ\n",
        "epochs = 100  # エポック数\n",
        "batch_size = 16  # バッチサイズ（GPUメモリに応じて調整）\n",
        "img_size = 640  # 画像サイズ\n",
        "device = 0  # GPU使用（0: GPU, cpu: CPU）\n",
        "\n",
        "# 出力先（ローカルストレージ）\n",
        "project_path = \"/content/tmp/runs\"\n",
        "run_name = f\"yolov5n_kaggle_{split}\"\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"学習設定\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"データセット: {data_path}\")\n",
        "print(f\"エポック数: {epochs}\")\n",
        "print(f\"バッチサイズ: {batch_size}\")\n",
        "print(f\"画像サイズ: {img_size}\")\n",
        "print(f\"デバイス: {'GPU' if device == 0 else 'CPU'}\")\n",
        "print(f\"出力先: {project_path}/{run_name}\")\n",
        "print(f\"\\nクラス数: {len(CLASSES)} クラス\")\n",
        "print(f\"クラス: {', '.join(CLASSES)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 学習の実行\n",
        "\n",
        "**注意**: このセルは長時間かかります（数時間）。GPUランタイムを使用してください。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 学習の実行\n",
        "print(\"=\" * 80)\n",
        "print(\"学習開始\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"開始時刻: {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print()\n",
        "\n",
        "# 学習実行\n",
        "results = model.train(\n",
        "    data=data_path,\n",
        "    epochs=epochs,\n",
        "    batch=batch_size,\n",
        "    imgsz=img_size,\n",
        "    device=device,\n",
        "    project=project_path,\n",
        "    name=run_name,\n",
        "    save=True,\n",
        "    save_period=10,  # 10エポックごとに保存\n",
        "    val=True,  # 検証データで評価\n",
        "    plots=True,  # 学習曲線をプロット\n",
        "    verbose=True,  # 詳細ログ\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"学習完了\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"終了時刻: {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 学習結果の確認\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 学習結果の確認\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "results_dir = Path(project_path) / run_name\n",
        "weights_dir = results_dir / \"weights\"\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"学習結果\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"結果ディレクトリ: {results_dir}\")\n",
        "\n",
        "# 重みファイルの確認\n",
        "if weights_dir.exists():\n",
        "    weight_files = list(weights_dir.glob('*.pt'))\n",
        "    print(f\"\\n重みファイル数: {len(weight_files)} 件\")\n",
        "    \n",
        "    for wf in sorted(weight_files):\n",
        "        size_mb = wf.stat().st_size / (1024 * 1024)\n",
        "        print(f\"  {wf.name}: {size_mb:.2f} MB\")\n",
        "    \n",
        "    # 最良モデル\n",
        "    best_model = weights_dir / \"best.pt\"\n",
        "    if best_model.exists():\n",
        "        print(f\"\\n✓ 最良モデル: {best_model.name}\")\n",
        "        print(f\"  サイズ: {best_model.stat().st_size / (1024 * 1024):.2f} MB\")\n",
        "    \n",
        "    # 最終モデル\n",
        "    last_model = weights_dir / \"last.pt\"\n",
        "    if last_model.exists():\n",
        "        print(f\"✓ 最終モデル: {last_model.name}\")\n",
        "        print(f\"  サイズ: {last_model.stat().st_size / (1024 * 1024):.2f} MB\")\n",
        "else:\n",
        "    print(\"\\n⚠️  重みファイルが見つかりません\")\n",
        "\n",
        "# 学習曲線の確認\n",
        "results_csv = results_dir / \"results.csv\"\n",
        "if results_csv.exists():\n",
        "    print(f\"\\n学習曲線データ: {results_csv}\")\n",
        "    print(\"  （results.csvをダウンロードしてExcel等で確認できます）\")\n",
        "\n",
        "# プロット画像の確認\n",
        "plot_files = list(results_dir.glob(\"*.png\"))\n",
        "if len(plot_files) > 0:\n",
        "    print(f\"\\nプロット画像数: {len(plot_files)} 件\")\n",
        "    for pf in plot_files:\n",
        "        print(f\"  {pf.name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 最良モデルをGoogle Driveに保存\n",
        "\n",
        "学習済みモデルをGoogle Driveに保存して、次回以降も使用できるようにします。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 最良モデルをGoogle Driveに保存\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 環境変数からパスを取得\n",
        "out_root = os.environ.get(\"OUT_ROOT\")\n",
        "if not out_root:\n",
        "    raise ValueError(\n",
        "        \"❌ エラー: OUT_ROOT環境変数が設定されていません。\\n\"\n",
        "        \"   セル3で環境変数を設定してください。\"\n",
        "    )\n",
        "\n",
        "# ローカルの最良モデル\n",
        "local_best_model = Path(project_path) / run_name / \"weights\" / \"best.pt\"\n",
        "\n",
        "if not local_best_model.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"❌ エラー: 最良モデルが見つかりません: {local_best_model}\\n\"\n",
        "        \"   先に学習を実行してください。\"\n",
        "    )\n",
        "\n",
        "# Google Driveの保存先\n",
        "drive_weights_dir = Path(out_root) / \"weights\"\n",
        "drive_weights_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ファイル名（タイムスタンプ付き）\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "drive_model_name = f\"yolov5n_kaggle_{split}_{timestamp}.pt\"\n",
        "drive_best_model = drive_weights_dir / drive_model_name\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"最良モデルをGoogle Driveに保存\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"ソース: {local_best_model}\")\n",
        "print(f\"保存先: {drive_best_model}\")\n",
        "\n",
        "# ファイルサイズを取得して進捗表示\n",
        "file_size = local_best_model.stat().st_size\n",
        "size_mb = file_size / (1024 * 1024)\n",
        "print(f\"\\nファイルサイズ: {size_mb:.2f} MB\")\n",
        "print(\"コピー中...\")\n",
        "\n",
        "# コピー（大きなファイルの場合は進捗表示）\n",
        "if file_size > 10 * 1024 * 1024:  # 10MB以上の場合\n",
        "    # チャンクごとにコピーして進捗表示\n",
        "    chunk_size = 1024 * 1024  # 1MB\n",
        "    with open(local_best_model, 'rb') as src, open(drive_best_model, 'wb') as dst:\n",
        "        with tqdm(total=file_size, unit='B', unit_scale=True, desc=\"コピー中\") as pbar:\n",
        "            while True:\n",
        "                chunk = src.read(chunk_size)\n",
        "                if not chunk:\n",
        "                    break\n",
        "                dst.write(chunk)\n",
        "                pbar.update(len(chunk))\n",
        "else:\n",
        "    # 小さいファイルは通常のコピー\n",
        "    shutil.copy2(local_best_model, drive_best_model)\n",
        "\n",
        "print(f\"\\n✓ 保存完了\")\n",
        "print(f\"  ファイル名: {drive_model_name}\")\n",
        "print(f\"  サイズ: {size_mb:.2f} MB\")\n",
        "print(f\"\\n次回以降は以下のパスから読み込めます:\")\n",
        "print(f\"  {drive_best_model}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
