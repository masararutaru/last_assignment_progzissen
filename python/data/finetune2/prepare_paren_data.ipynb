{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# æ‹¬å¼§ç”¨æ“¬ä¼¼æ¤œå‡ºãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ\n",
        "\n",
        "## ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®ç›®çš„\n",
        "\n",
        "Kaggleã®ã€ŒHandwritten math symbols datasetï¼ˆxainanoï¼‰ã€ã‹ã‚‰æ‹¬å¼§ `(` ã¨ `)` ã®å˜ä½“ç”»åƒã‚’å–å¾—ã—ã€\n",
        "æ“¬ä¼¼æ¤œå‡ºãƒ‡ãƒ¼ã‚¿ï¼ˆYOLOå½¢å¼ï¼‰ã‚’ç”Ÿæˆã—ã¾ã™ã€‚\n",
        "\n",
        "### å‡¦ç†ã®æµã‚Œ\n",
        "1. Kaggleã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
        "2. æ‹¬å¼§ `(` ã¨ `)` ã®å˜ä½“ç”»åƒã‚’æŠ½å‡º\n",
        "3. å„ç”»åƒã‹ã‚‰é»’ç”»ç´ ã®å¤–æ¥çŸ©å½¢ã‚’è¨ˆç®—ï¼ˆbboxä½œæˆï¼‰\n",
        "4. ãã®è¨˜å·ã‚’640x640ã®ç™½ã‚­ãƒ£ãƒ³ãƒã‚¹ã«è²¼ã‚‹ï¼ˆä½ç½®ã¨å¤§ãã•ã‚’ãƒ©ãƒ³ãƒ€ãƒ åŒ–ï¼‰\n",
        "5. è²¼ã£ãŸä½ç½®ãƒ»ã‚µã‚¤ã‚ºã‹ã‚‰æ­£ã—ã„bboxã‚’YOLOå½¢å¼ã§ä¿å­˜\n",
        "6. æ—¢å­˜ã®Aidaãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨æ··ãœã‚‹æº–å‚™ï¼ˆtaråŒ–ãƒ»S3ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼‰\n",
        "\n",
        "### å‡ºåŠ›\n",
        "- `/content/tmp/paren_synthetic/train/images/` - ç”Ÿæˆã•ã‚ŒãŸç”»åƒ\n",
        "- `/content/tmp/paren_synthetic/train/labels/` - YOLOå½¢å¼ã®ãƒ©ãƒ™ãƒ«\n",
        "- `/content/tmp/paren_synthetic/paren_synthetic.tar` - tarã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ï¼ˆS3ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”¨ï¼‰\n",
        "\n",
        "### æ³¨æ„ç‚¹\n",
        "- ã‚¯ãƒ©ã‚¹ID: `(` ã¯42ã€`)` ã¯43ï¼ˆæ—¢å­˜ã®YOLOãƒ¢ãƒ‡ãƒ«ã¨ä¸€è‡´ï¼‰\n",
        "- ç”Ÿæˆæšæ•°: å„1500ã€œ3000æšï¼ˆåˆè¨ˆ3000ã€œ6000æšï¼‰\n",
        "- ç”»åƒã‚µã‚¤ã‚º: 640x640ï¼ˆYOLOå­¦ç¿’ç”¨ï¼‰\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ã‚»ãƒ«0: AWSèªè¨¼è¨­å®š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"AKIAxxxxxxxxxxxxxxxx\"  # åŸ‹ã‚ã¦ã­ï¼ï¼ï¼ï¼ï¼ï¼ï¼\n",
        "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"xxxxxxxxxxxxxxxxxxxx\"  # åŸ‹ã‚ã¦ã­ï¼ï¼ï¼ï¼ï¼ï¼ï¼\n",
        "os.environ[\"AWS_DEFAULT_REGION\"] = \"ap-northeast-1\"\n",
        "\n",
        "print(\"AWS env set\")\n",
        "\n",
        "assert \"AWS_ACCESS_KEY_ID\" in os.environ, \"AWS_ACCESS_KEY_ID not set\"\n",
        "assert \"AWS_SECRET_ACCESS_KEY\" in os.environ, \"AWS_SECRET_ACCESS_KEY not set\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ã‚»ãƒ«0.5: Kaggleèªè¨¼è¨­å®š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = 'masapirika'\n",
        "os.environ['KAGGLE_KEY'] = '================'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ã‚»ãƒ«1: è¨­å®šï¼ˆã“ã“ã ã‘è§¦ã‚Œã°OKï¼‰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# è¨­å®šï¼ˆã“ã“ã ã‘å¤‰æ›´ã™ã‚Œã°OKï¼‰\n",
        "# ============================================\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# ===== Kaggleè¨­å®š =====\n",
        "KAGGLE_DATASET = \"xainano/handwrittenmathsymbols\"  # æ‹¬å¼§ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ\n",
        "KAGGLE_DOWNLOAD_DIR = Path(\"/content/tmp/kaggle_paren\")\n",
        "\n",
        "# ===== å‡ºåŠ›è¨­å®š =====\n",
        "OUT_DIR = Path(\"/content/tmp/paren_synthetic\")\n",
        "TRAIN_IMAGES_DIR = OUT_DIR / \"train\" / \"images\"\n",
        "TRAIN_LABELS_DIR = OUT_DIR / \"train\" / \"labels\"\n",
        "\n",
        "# ===== ç”Ÿæˆè¨­å®š =====\n",
        "# ã‚¯ãƒ©ã‚¹IDï¼ˆæ—¢å­˜ã®YOLOãƒ¢ãƒ‡ãƒ«ã¨ä¸€è‡´ï¼‰\n",
        "CLASS_ID_LPAREN = 42  # (\n",
        "CLASS_ID_RPAREN = 43  # )\n",
        "\n",
        "# ç”Ÿæˆæšæ•°ï¼ˆå„ã‚¯ãƒ©ã‚¹ï¼‰\n",
        "NUM_SAMPLES_LPAREN = 2500  # ( ã®ç”Ÿæˆæšæ•°ï¼ˆ1500ã€œ3000ã®ç¯„å›²ã§èª¿æ•´ï¼‰\n",
        "NUM_SAMPLES_RPAREN = 2500  # ) ã®ç”Ÿæˆæšæ•°ï¼ˆ1500ã€œ3000ã®ç¯„å›²ã§èª¿æ•´ï¼‰\n",
        "\n",
        "# ç”»åƒã‚µã‚¤ã‚ºï¼ˆYOLOå­¦ç¿’ç”¨ï¼‰\n",
        "CANVAS_SIZE = 640  # 640x640\n",
        "\n",
        "# è²¼ã‚Šä»˜ã‘æ™‚ã®ãƒ©ãƒ³ãƒ€ãƒ åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
        "MIN_SCALE = 0.5  # æœ€å°ã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆå…ƒç”»åƒã«å¯¾ã™ã‚‹ï¼‰â† 0.3ã‹ã‚‰0.5ã«å¤‰æ›´ï¼ˆbboxãŒå°ã•ã™ãã‚‹ã®ã‚’é˜²ãï¼‰\n",
        "MAX_SCALE = 1.2  # æœ€å¤§ã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆå…ƒç”»åƒã«å¯¾ã™ã‚‹ï¼‰â† 0.8ã‹ã‚‰1.2ã«å¤‰æ›´ï¼ˆã‚ˆã‚Šå¤§ãã‚ã«ï¼‰\n",
        "MIN_MARGIN = 20  # æœ€å°ãƒãƒ¼ã‚¸ãƒ³ï¼ˆãƒ”ã‚¯ã‚»ãƒ«ï¼‰\n",
        "MAX_MARGIN = 100  # æœ€å¤§ãƒãƒ¼ã‚¸ãƒ³ï¼ˆãƒ”ã‚¯ã‚»ãƒ«ï¼‰\n",
        "# æ³¨æ„: bboxãŒç”»åƒã®5%ä»¥ä¸Šï¼ˆ640x640ãªã‚‰32x32ãƒ”ã‚¯ã‚»ãƒ«ä»¥ä¸Šï¼‰ã«ãªã‚‹ã‚ˆã†ã«èª¿æ•´\n",
        "MIN_BBOX_SIZE = 32  # æœ€å°bboxã‚µã‚¤ã‚ºï¼ˆãƒ”ã‚¯ã‚»ãƒ«ï¼‰\n",
        "\n",
        "# ===== S3è¨­å®š =====\n",
        "S3_BUCKET = \"km62m-ml-storage\"  # S3ãƒã‚±ãƒƒãƒˆå\n",
        "S3_PREFIX = \"yolo-dataset/finetune2-paren\"  # S3ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹\n",
        "UPLOAD_TO_S3 = True  # Trueã«ã™ã‚‹ã¨S3ã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
        "\n",
        "# ===== ãã®ä»– =====\n",
        "SEED = 42  # å†ç¾æ€§ã®ãŸã‚ã®ã‚·ãƒ¼ãƒ‰\n",
        "CLEAN_OUT_DIR = False  # Trueã«ã™ã‚‹ã¨æ—¢å­˜ã®OUT_DIRã‚’å‰Šé™¤\n",
        "FORCE_REBUILD_TAR = False  # Trueã«ã™ã‚‹ã¨æ—¢å­˜ã®tarãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ä½œæˆï¼ˆS3ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‰ã«å†ç”Ÿæˆã—ãŸã„å ´åˆï¼‰\n",
        "FORCE_UPLOAD_S3 = True  # Trueã«ã™ã‚‹ã¨æ—¢å­˜ã®S3ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸Šæ›¸ãã€Falseã«ã™ã‚‹ã¨ã‚¹ã‚­ãƒƒãƒ—\n",
        "\n",
        "print(\"âœ“ è¨­å®šå®Œäº†\")\n",
        "print(f\"  KAGGLE_DATASET: {KAGGLE_DATASET}\")\n",
        "print(f\"  OUT_DIR: {OUT_DIR}\")\n",
        "print(f\"  NUM_SAMPLES_LPAREN: {NUM_SAMPLES_LPAREN}\")\n",
        "print(f\"  NUM_SAMPLES_RPAREN: {NUM_SAMPLES_RPAREN}\")\n",
        "print(f\"  CANVAS_SIZE: {CANVAS_SIZE}x{CANVAS_SIZE}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ã‚»ãƒ«2: ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
        "# ============================================\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_package(package, import_name=None):\n",
        "    \"\"\"\n",
        "    ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰\n",
        "    \"\"\"\n",
        "    if import_name is None:\n",
        "        import_name = package\n",
        "    \n",
        "    try:\n",
        "        __import__(import_name)\n",
        "        print(f\"âœ“ {package} ã¯æ—¢ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿\")\n",
        "    except ImportError:\n",
        "        print(f\"ğŸ“¦ {package} ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
        "        print(f\"âœ“ {package} ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†\")\n",
        "\n",
        "# å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸\n",
        "packages = [\n",
        "    (\"kaggle\", None),\n",
        "    (\"Pillow\", \"PIL\"),\n",
        "    (\"numpy\", None),\n",
        "    (\"tqdm\", None),\n",
        "]\n",
        "\n",
        "for pkg_info in packages:\n",
        "    if isinstance(pkg_info, tuple):\n",
        "        pkg, import_name = pkg_info\n",
        "    else:\n",
        "        pkg, import_name = pkg_info, None\n",
        "    install_package(pkg, import_name)\n",
        "\n",
        "# AWS CLI\n",
        "try:\n",
        "    result = subprocess.run([\"aws\", \"--version\"], capture_output=True, text=True)\n",
        "    print(f\"\\nâœ“ AWS CLI ã¯æ—¢ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿: {result.stdout.strip()}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"\\nğŸ“¦ AWS CLI ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...\")\n",
        "    subprocess.check_call([\"pip\", \"install\", \"-q\", \"awscli\"])\n",
        "    print(\"âœ“ AWS CLI ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†\")\n",
        "\n",
        "print(\"\\nâœ“ å…¨ã¦ã®ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®æº–å‚™å®Œäº†\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ã‚»ãƒ«3: Kaggleã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# Kaggleã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
        "# ============================================\n",
        "\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"Kaggleã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Kaggleèªè¨¼ã®ç¢ºèª\n",
        "has_env = bool(os.getenv(\"KAGGLE_USERNAME\")) and bool(os.getenv(\"KAGGLE_KEY\"))\n",
        "has_json = (Path.home() / \".config\" / \"kaggle\" / \"kaggle.json\").exists() or (Path.home() / \".kaggle\" / \"kaggle.json\").exists()\n",
        "\n",
        "if not (has_env or has_json):\n",
        "    print(\"âš ï¸ Kaggleèªè¨¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
        "    print(\"  ã‚»ãƒ«0.5ã§KAGGLE_USERNAMEã¨KAGGLE_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„\")\n",
        "    raise ValueError(\"Kaggleèªè¨¼ãŒå¿…è¦ã§ã™\")\n",
        "else:\n",
        "    print(\"âœ“ Kaggleèªè¨¼OK\")\n",
        "\n",
        "# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å…ˆã®æº–å‚™\n",
        "KAGGLE_DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Kaggle CLIã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
        "print(f\"\\nğŸ“¥ Kaggleã‹ã‚‰DLä¸­: {KAGGLE_DATASET}\")\n",
        "try:\n",
        "    subprocess.run(\n",
        "        [\"kaggle\", \"datasets\", \"download\", \"-d\", KAGGLE_DATASET, \"-p\", str(KAGGLE_DOWNLOAD_DIR)],\n",
        "        check=True\n",
        "    )\n",
        "    print(\"âœ“ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}\")\n",
        "    raise\n",
        "\n",
        "# zipãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª\n",
        "zip_files = sorted(KAGGLE_DOWNLOAD_DIR.glob(\"*.zip\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "if zip_files:\n",
        "    zip_path = zip_files[0]\n",
        "    size_mb = zip_path.stat().st_size / (1024 ** 2)\n",
        "    print(f\"\\nâœ“ zipãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª: {zip_path.name} ({size_mb:.2f} MB)\")\n",
        "else:\n",
        "    raise FileNotFoundError(\"zipãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ã‚»ãƒ«4: zipãƒ•ã‚¡ã‚¤ãƒ«ã‚’å±•é–‹ã—ã¦æ‹¬å¼§ç”»åƒã‚’æŠ½å‡º\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# zipãƒ•ã‚¡ã‚¤ãƒ«ã‚’å±•é–‹ã—ã¦æ‹¬å¼§ç”»åƒã‚’æŠ½å‡º\n",
        "# ============================================\n",
        "\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"zipãƒ•ã‚¡ã‚¤ãƒ«ã‚’å±•é–‹ã—ã¦æ‹¬å¼§ç”»åƒã‚’æŠ½å‡º\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# zipãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹\n",
        "zip_files = sorted(KAGGLE_DOWNLOAD_DIR.glob(\"*.zip\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "if not zip_files:\n",
        "    raise FileNotFoundError(\"zipãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
        "zip_path = zip_files[0]\n",
        "\n",
        "# å±•é–‹å…ˆ\n",
        "EXTRACT_DIR = KAGGLE_DOWNLOAD_DIR / \"extracted\"\n",
        "EXTRACT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# zipãƒ•ã‚¡ã‚¤ãƒ«ã‚’å±•é–‹\n",
        "print(f\"\\nğŸ“¦ zipãƒ•ã‚¡ã‚¤ãƒ«ã‚’å±•é–‹ä¸­: {zip_path.name}\")\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    file_list = zip_ref.namelist()\n",
        "    for file_info in tqdm(file_list, desc=\"å±•é–‹ä¸­\"):\n",
        "        zip_ref.extract(file_info, EXTRACT_DIR)\n",
        "\n",
        "print(f\"\\nâœ“ å±•é–‹å®Œäº†: {EXTRACT_DIR}\")\n",
        "\n",
        "# æ‹¬å¼§ç”»åƒã‚’æ¢ã™ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã‚„ãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ ã«å¿œã˜ã¦èª¿æ•´ãŒå¿…è¦ï¼‰\n",
        "print(f\"\\nğŸ” æ‹¬å¼§ç”»åƒã‚’æ¤œç´¢ä¸­...\")\n",
        "\n",
        "# ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†å¸°çš„ã«æ¤œç´¢\n",
        "image_extensions = {'.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG'}\n",
        "all_images = []\n",
        "for ext in image_extensions:\n",
        "    all_images.extend(EXTRACT_DIR.rglob(f\"*{ext}\"))\n",
        "\n",
        "print(f\"  è¦‹ã¤ã‹ã£ãŸç”»åƒãƒ•ã‚¡ã‚¤ãƒ«: {len(all_images)} ä»¶\")\n",
        "\n",
        "# æ‹¬å¼§ç”»åƒã‚’åˆ†é¡ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã‚„ãƒ‘ã‚¹ã‹ã‚‰åˆ¤å®šï¼‰\n",
        "lparen_images = []\n",
        "rparen_images = []\n",
        "\n",
        "for img_path in all_images:\n",
        "    path_str = str(img_path).lower()\n",
        "    name = img_path.stem.lower()\n",
        "    \n",
        "    # å·¦æ‹¬å¼§ã®ãƒ‘ã‚¿ãƒ¼ãƒ³\n",
        "    if any(pattern in path_str or pattern in name for pattern in ['lparen', 'left_paren', 'leftparen', '(', 'open_paren']):\n",
        "        lparen_images.append(img_path)\n",
        "    # å³æ‹¬å¼§ã®ãƒ‘ã‚¿ãƒ¼ãƒ³\n",
        "    elif any(pattern in path_str or pattern in name for pattern in ['rparen', 'right_paren', 'rightparen', ')', 'close_paren']):\n",
        "        rparen_images.append(img_path)\n",
        "\n",
        "print(f\"\\nâœ“ æ‹¬å¼§ç”»åƒã‚’åˆ†é¡\")\n",
        "print(f\"  ( ã®ç”»åƒ: {len(lparen_images)} ä»¶\")\n",
        "print(f\"  ) ã®ç”»åƒ: {len(rparen_images)} ä»¶\")\n",
        "\n",
        "if len(lparen_images) == 0 and len(rparen_images) == 0:\n",
        "    print(\"\\nâš ï¸  è­¦å‘Š: æ‹¬å¼§ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\")\n",
        "    print(\"  ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ã‚’ç¢ºèªã—ã¦ãã ã•ã„\")\n",
        "    print(\"\\nè¦‹ã¤ã‹ã£ãŸç”»åƒã®ä¾‹ï¼ˆæœ€åˆã®10ä»¶ï¼‰:\")\n",
        "    for img_path in all_images[:10]:\n",
        "        print(f\"    {img_path.relative_to(EXTRACT_DIR)}\")\n",
        "\n",
        "print(f\"\\nâœ“ ç”»åƒæŠ½å‡ºå®Œäº†\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# æ“¬ä¼¼æ¤œå‡ºãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ\n",
        "# ============================================\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import uuid\n",
        "import shutil\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"æ“¬ä¼¼æ¤œå‡ºãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# ã‚·ãƒ¼ãƒ‰ã‚’è¨­å®š\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æº–å‚™\n",
        "if CLEAN_OUT_DIR and OUT_DIR.exists():\n",
        "    print(f\"ğŸ—‘ï¸  æ—¢å­˜ã®OUT_DIRã‚’å‰Šé™¤: {OUT_DIR}\")\n",
        "    shutil.rmtree(OUT_DIR)\n",
        "\n",
        "TRAIN_IMAGES_DIR.mkdir(parents=True, exist_ok=True)\n",
        "TRAIN_LABELS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def get_bounding_box(image: Image.Image) -> tuple:\n",
        "    \"\"\"\n",
        "    ç”»åƒã‹ã‚‰é»’ç”»ç´ ã®å¤–æ¥çŸ©å½¢ã‚’è¨ˆç®—\n",
        "    æˆ»ã‚Šå€¤: (xmin, ymin, xmax, ymax) ãƒ”ã‚¯ã‚»ãƒ«åº§æ¨™\n",
        "    \"\"\"\n",
        "    # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ã«å¤‰æ›\n",
        "    if image.mode != 'L':\n",
        "        image = image.convert('L')\n",
        "    \n",
        "    # numpyé…åˆ—ã«å¤‰æ›\n",
        "    img_array = np.array(image)\n",
        "    \n",
        "    # é»’ç”»ç´ ï¼ˆå€¤ãŒå°ã•ã„ç”»ç´ ï¼‰ã‚’æ¢ã™\n",
        "    # é–¾å€¤: 128ä»¥ä¸‹ã‚’é»’ã¨ã¿ãªã™ï¼ˆå¿…è¦ã«å¿œã˜ã¦èª¿æ•´ï¼‰\n",
        "    black_pixels = np.where(img_array < 128)\n",
        "    \n",
        "    if len(black_pixels[0]) == 0:\n",
        "        # é»’ç”»ç´ ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ç”»åƒå…¨ä½“ã‚’è¿”ã™\n",
        "        return (0, 0, image.width, image.height)\n",
        "    \n",
        "    ymin = int(np.min(black_pixels[0]))\n",
        "    ymax = int(np.max(black_pixels[0]))\n",
        "    xmin = int(np.min(black_pixels[1]))\n",
        "    xmax = int(np.max(black_pixels[1]))\n",
        "    \n",
        "    # å°‘ã—ãƒãƒ¼ã‚¸ãƒ³ã‚’è¿½åŠ ï¼ˆä½™ç™½ã‚’ç¢ºä¿ï¼‰\n",
        "    margin = 2\n",
        "    xmin = max(0, xmin - margin)\n",
        "    ymin = max(0, ymin - margin)\n",
        "    xmax = min(image.width, xmax + margin)\n",
        "    ymax = min(image.height, ymax + margin)\n",
        "    \n",
        "    return (xmin, ymin, xmax, ymax)\n",
        "\n",
        "def create_synthetic_image(source_image: Image.Image, class_id: int, uuid_str: str) -> tuple:\n",
        "    \"\"\"\n",
        "    å˜ä½“ç”»åƒã‹ã‚‰æ“¬ä¼¼æ¤œå‡ºç”»åƒã‚’ç”Ÿæˆ\n",
        "    æˆ»ã‚Šå€¤: (ç”Ÿæˆç”»åƒ, YOLOå½¢å¼bbox)\n",
        "    \"\"\"\n",
        "    # å¤–æ¥çŸ©å½¢ã‚’è¨ˆç®—\n",
        "    xmin_src, ymin_src, xmax_src, ymax_src = get_bounding_box(source_image)\n",
        "    \n",
        "    # å¤–æ¥çŸ©å½¢ã®ã‚µã‚¤ã‚º\n",
        "    bbox_width = xmax_src - xmin_src\n",
        "    bbox_height = ymax_src - ymin_src\n",
        "    \n",
        "    if bbox_width <= 0 or bbox_height <= 0:\n",
        "        # ç„¡åŠ¹ãªbboxã®å ´åˆã¯ç”»åƒå…¨ä½“ã‚’ä½¿ç”¨\n",
        "        bbox_width = source_image.width\n",
        "        bbox_height = source_image.height\n",
        "        xmin_src, ymin_src = 0, 0\n",
        "    \n",
        "    # ã‚¹ã‚±ãƒ¼ãƒ«ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«æ±ºå®š\n",
        "    scale = random.uniform(MIN_SCALE, MAX_SCALE)\n",
        "    \n",
        "    # æ–°ã—ã„ã‚µã‚¤ã‚ºã‚’è¨ˆç®—ï¼ˆã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’ä¿æŒï¼‰\n",
        "    new_width = int(bbox_width * scale)\n",
        "    new_height = int(bbox_height * scale)\n",
        "    \n",
        "    # æœ€å°ã‚µã‚¤ã‚ºã‚’ç¢ºä¿ï¼ˆYOLOå­¦ç¿’ã«é©ã—ãŸã‚µã‚¤ã‚ºï¼‰\n",
        "    # 640x640ã®ç”»åƒã«å¯¾ã—ã¦ã€bboxã¯5%ä»¥ä¸Šï¼ˆ32x32ãƒ”ã‚¯ã‚»ãƒ«ä»¥ä¸Šï¼‰ãŒæ¨å¥¨\n",
        "    new_width = max(MIN_BBOX_SIZE, new_width)\n",
        "    new_height = max(MIN_BBOX_SIZE, new_height)\n",
        "    \n",
        "    # å¤–æ¥çŸ©å½¢éƒ¨åˆ†ã‚’åˆ‡ã‚Šå‡ºã—ã¦ãƒªã‚µã‚¤ã‚º\n",
        "    cropped = source_image.crop((xmin_src, ymin_src, xmax_src, ymax_src))\n",
        "    resized = cropped.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
        "    \n",
        "    # 640x640ã®ç™½ã‚­ãƒ£ãƒ³ãƒã‚¹ã‚’ä½œæˆ\n",
        "    canvas = Image.new('RGB', (CANVAS_SIZE, CANVAS_SIZE), color='white')\n",
        "    \n",
        "    # è²¼ã‚Šä»˜ã‘ä½ç½®ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«æ±ºå®šï¼ˆãƒãƒ¼ã‚¸ãƒ³ã‚’è€ƒæ…®ï¼‰\n",
        "    margin_x = random.randint(MIN_MARGIN, MAX_MARGIN)\n",
        "    margin_y = random.randint(MIN_MARGIN, MAX_MARGIN)\n",
        "    \n",
        "    # è²¼ã‚Šä»˜ã‘ä½ç½®ï¼ˆå·¦ä¸Šåº§æ¨™ï¼‰\n",
        "    paste_x = margin_x\n",
        "    paste_y = margin_y\n",
        "    \n",
        "    # ã‚­ãƒ£ãƒ³ãƒã‚¹ã‹ã‚‰ã¯ã¿å‡ºã•ãªã„ã‚ˆã†ã«èª¿æ•´\n",
        "    paste_x = min(paste_x, CANVAS_SIZE - new_width - 10)\n",
        "    paste_y = min(paste_y, CANVAS_SIZE - new_height - 10)\n",
        "    paste_x = max(0, paste_x)\n",
        "    paste_y = max(0, paste_y)\n",
        "    \n",
        "    # ç”»åƒã‚’è²¼ã‚Šä»˜ã‘\n",
        "    canvas.paste(resized, (paste_x, paste_y))\n",
        "    \n",
        "    # YOLOå½¢å¼ã®bboxã‚’è¨ˆç®—ï¼ˆæ­£è¦åŒ–åº§æ¨™ï¼‰\n",
        "    center_x = (paste_x + new_width / 2) / CANVAS_SIZE\n",
        "    center_y = (paste_y + new_height / 2) / CANVAS_SIZE\n",
        "    width_norm = new_width / CANVAS_SIZE\n",
        "    height_norm = new_height / CANVAS_SIZE\n",
        "    \n",
        "    # 0-1ã®ç¯„å›²ã«ã‚¯ãƒªãƒƒãƒ—\n",
        "    center_x = max(0.0, min(1.0, center_x))\n",
        "    center_y = max(0.0, min(1.0, center_y))\n",
        "    width_norm = max(0.0, min(1.0, width_norm))\n",
        "    height_norm = max(0.0, min(1.0, height_norm))\n",
        "    \n",
        "    return canvas, (class_id, center_x, center_y, width_norm, height_norm)\n",
        "\n",
        "# å·¦æ‹¬å¼§ `(` ã‚’ç”Ÿæˆ\n",
        "print(f\"\\nğŸ“ å·¦æ‹¬å¼§ `(` ã®æ“¬ä¼¼æ¤œå‡ºãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆä¸­...\")\n",
        "if len(lparen_images) == 0:\n",
        "    print(\"âš ï¸  è­¦å‘Š: å·¦æ‹¬å¼§ã®ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\")\n",
        "    print(\"  ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™\")\n",
        "else:\n",
        "    generated_count = 0\n",
        "    for i in tqdm(range(NUM_SAMPLES_LPAREN), desc=\"ç”Ÿæˆä¸­\"):\n",
        "        # ãƒ©ãƒ³ãƒ€ãƒ ã«å…ƒç”»åƒã‚’é¸æŠ\n",
        "        source_img_path = random.choice(lparen_images)\n",
        "        \n",
        "        try:\n",
        "            # ç”»åƒã‚’èª­ã¿è¾¼ã¿\n",
        "            source_img = Image.open(source_img_path)\n",
        "            \n",
        "            # UUIDã‚’ç”Ÿæˆ\n",
        "            uuid_str = f\"lparen_{uuid.uuid4().hex[:8]}_{i:06d}\"\n",
        "            \n",
        "            # æ“¬ä¼¼æ¤œå‡ºç”»åƒã‚’ç”Ÿæˆ\n",
        "            synthetic_img, yolo_bbox = create_synthetic_image(source_img, CLASS_ID_LPAREN, uuid_str)\n",
        "            \n",
        "            # ç”»åƒã‚’ä¿å­˜\n",
        "            img_path = TRAIN_IMAGES_DIR / f\"{uuid_str}.png\"\n",
        "            synthetic_img.save(img_path)\n",
        "            \n",
        "            # ãƒ©ãƒ™ãƒ«ã‚’ä¿å­˜\n",
        "            label_path = TRAIN_LABELS_DIR / f\"{uuid_str}.txt\"\n",
        "            with open(label_path, 'w') as f:\n",
        "                class_id, cx, cy, w, h = yolo_bbox\n",
        "                f.write(f\"{class_id} {cx:.6f} {cy:.6f} {w:.6f} {h:.6f}\\n\")\n",
        "            \n",
        "            generated_count += 1\n",
        "        except Exception as e:\n",
        "            print(f\"\\nâš ï¸  è­¦å‘Š: {source_img_path} ã®å‡¦ç†ã«å¤±æ•—: {e}\")\n",
        "            continue\n",
        "    \n",
        "    print(f\"\\nâœ“ å·¦æ‹¬å¼§ `(` ã®ç”Ÿæˆå®Œäº†: {generated_count} ä»¶\")\n",
        "\n",
        "# å³æ‹¬å¼§ `)` ã‚’ç”Ÿæˆ\n",
        "print(f\"\\nğŸ“ å³æ‹¬å¼§ `)` ã®æ“¬ä¼¼æ¤œå‡ºãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆä¸­...\")\n",
        "if len(rparen_images) == 0:\n",
        "    print(\"âš ï¸  è­¦å‘Š: å³æ‹¬å¼§ã®ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\")\n",
        "    print(\"  ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™\")\n",
        "else:\n",
        "    generated_count = 0\n",
        "    for i in tqdm(range(NUM_SAMPLES_RPAREN), desc=\"ç”Ÿæˆä¸­\"):\n",
        "        # ãƒ©ãƒ³ãƒ€ãƒ ã«å…ƒç”»åƒã‚’é¸æŠ\n",
        "        source_img_path = random.choice(rparen_images)\n",
        "        \n",
        "        try:\n",
        "            # ç”»åƒã‚’èª­ã¿è¾¼ã¿\n",
        "            source_img = Image.open(source_img_path)\n",
        "            \n",
        "            # UUIDã‚’ç”Ÿæˆ\n",
        "            uuid_str = f\"rparen_{uuid.uuid4().hex[:8]}_{i:06d}\"\n",
        "            \n",
        "            # æ“¬ä¼¼æ¤œå‡ºç”»åƒã‚’ç”Ÿæˆ\n",
        "            synthetic_img, yolo_bbox = create_synthetic_image(source_img, CLASS_ID_RPAREN, uuid_str)\n",
        "            \n",
        "            # ç”»åƒã‚’ä¿å­˜\n",
        "            img_path = TRAIN_IMAGES_DIR / f\"{uuid_str}.png\"\n",
        "            synthetic_img.save(img_path)\n",
        "            \n",
        "            # ãƒ©ãƒ™ãƒ«ã‚’ä¿å­˜\n",
        "            label_path = TRAIN_LABELS_DIR / f\"{uuid_str}.txt\"\n",
        "            with open(label_path, 'w') as f:\n",
        "                class_id, cx, cy, w, h = yolo_bbox\n",
        "                f.write(f\"{class_id} {cx:.6f} {cy:.6f} {w:.6f} {h:.6f}\\n\")\n",
        "            \n",
        "            generated_count += 1\n",
        "        except Exception as e:\n",
        "            print(f\"\\nâš ï¸  è­¦å‘Š: {source_img_path} ã®å‡¦ç†ã«å¤±æ•—: {e}\")\n",
        "            continue\n",
        "    \n",
        "    print(f\"\\nâœ“ å³æ‹¬å¼§ `)` ã®ç”Ÿæˆå®Œäº†: {generated_count} ä»¶\")\n",
        "\n",
        "# ç”Ÿæˆçµæœã®ç¢ºèª\n",
        "generated_images = list(TRAIN_IMAGES_DIR.glob(\"*.png\"))\n",
        "generated_labels = list(TRAIN_LABELS_DIR.glob(\"*.txt\"))\n",
        "\n",
        "print(f\"\\n\" + \"=\" * 80)\n",
        "print(\"ç”Ÿæˆçµæœ\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"  ç”Ÿæˆç”»åƒæ•°: {len(generated_images)} ä»¶\")\n",
        "print(f\"  ç”Ÿæˆãƒ©ãƒ™ãƒ«æ•°: {len(generated_labels)} ä»¶\")\n",
        "\n",
        "# 1å¯¾1å¯¾å¿œã®ç¢ºèª\n",
        "image_uuids = {f.stem for f in generated_images}\n",
        "label_uuids = {f.stem for f in generated_labels}\n",
        "matched = image_uuids & label_uuids\n",
        "\n",
        "print(f\"\\n1å¯¾1å¯¾å¿œç¢ºèª:\")\n",
        "print(f\"  ãƒãƒƒãƒã—ãŸãƒšã‚¢: {len(matched)}/{len(generated_images)}\")\n",
        "\n",
        "if len(matched) == len(generated_images) == len(generated_labels):\n",
        "    print(f\"\\nâœ“ å®Œç’§ï¼å…¨ã¦ã®ç”»åƒã¨ãƒ©ãƒ™ãƒ«ãŒ1å¯¾1ã§å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\")\n",
        "else:\n",
        "    print(f\"\\nâš ï¸  è­¦å‘Š: ä¸€éƒ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¯¾å¿œã—ã¦ã„ã¾ã›ã‚“\")\n",
        "\n",
        "print(f\"\\nâœ“ æ“¬ä¼¼æ¤œå‡ºãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ã‚»ãƒ«5.5: bboxã‚µã‚¤ã‚ºã®çµ±è¨ˆç¢ºèªï¼ˆé‡è¦ï¼‰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# bboxã‚µã‚¤ã‚ºã®çµ±è¨ˆç¢ºèªï¼ˆé‡è¦ï¼‰\n",
        "# ============================================\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"bboxã‚µã‚¤ã‚ºã®çµ±è¨ˆç¢ºèª\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "bbox_widths = []\n",
        "bbox_heights = []\n",
        "bbox_areas = []\n",
        "\n",
        "for label_path in TRAIN_LABELS_DIR.glob(\"*.txt\"):\n",
        "    with open(label_path, 'r') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) >= 5:\n",
        "                width_norm = float(parts[3])\n",
        "                height_norm = float(parts[4])\n",
        "                \n",
        "                # ãƒ”ã‚¯ã‚»ãƒ«ã‚µã‚¤ã‚ºã«å¤‰æ›\n",
        "                width_px = width_norm * CANVAS_SIZE\n",
        "                height_px = height_norm * CANVAS_SIZE\n",
        "                area_px = width_px * height_px\n",
        "                \n",
        "                bbox_widths.append(width_px)\n",
        "                bbox_heights.append(height_px)\n",
        "                bbox_areas.append(area_px)\n",
        "\n",
        "if len(bbox_widths) > 0:\n",
        "    print(f\"\\nbboxã‚µã‚¤ã‚ºçµ±è¨ˆï¼ˆãƒ”ã‚¯ã‚»ãƒ«å˜ä½ã€ç”»åƒã‚µã‚¤ã‚º={CANVAS_SIZE}x{CANVAS_SIZE}ï¼‰:\")\n",
        "    print(f\"  å¹…:\")\n",
        "    print(f\"    å¹³å‡: {np.mean(bbox_widths):.1f} px\")\n",
        "    print(f\"    æœ€å°: {np.min(bbox_widths):.1f} px\")\n",
        "    print(f\"    æœ€å¤§: {np.max(bbox_widths):.1f} px\")\n",
        "    print(f\"  é«˜ã•:\")\n",
        "    print(f\"    å¹³å‡: {np.mean(bbox_heights):.1f} px\")\n",
        "    print(f\"    æœ€å°: {np.min(bbox_heights):.1f} px\")\n",
        "    print(f\"    æœ€å¤§: {np.max(bbox_heights):.1f} px\")\n",
        "    print(f\"  é¢ç©:\")\n",
        "    print(f\"    å¹³å‡: {np.mean(bbox_areas):.1f} pxÂ²\")\n",
        "    print(f\"    æœ€å°: {np.min(bbox_areas):.1f} pxÂ²\")\n",
        "    print(f\"    æœ€å¤§: {np.max(bbox_areas):.1f} pxÂ²\")\n",
        "    \n",
        "    # ç”»åƒã«å¯¾ã™ã‚‹å‰²åˆ\n",
        "    avg_width_ratio = np.mean(bbox_widths) / CANVAS_SIZE * 100\n",
        "    avg_height_ratio = np.mean(bbox_heights) / CANVAS_SIZE * 100\n",
        "    avg_area_ratio = np.mean(bbox_areas) / (CANVAS_SIZE * CANVAS_SIZE) * 100\n",
        "    \n",
        "    print(f\"\\nç”»åƒã«å¯¾ã™ã‚‹å‰²åˆ:\")\n",
        "    print(f\"  å¹…: å¹³å‡ {avg_width_ratio:.1f}%\")\n",
        "    print(f\"  é«˜ã•: å¹³å‡ {avg_height_ratio:.1f}%\")\n",
        "    print(f\"  é¢ç©: å¹³å‡ {avg_area_ratio:.2f}%\")\n",
        "    \n",
        "    # æ¨å¥¨å€¤ã¨ã®æ¯”è¼ƒ\n",
        "    min_width = np.min(bbox_widths)\n",
        "    min_height = np.min(bbox_heights)\n",
        "    min_area_ratio = (min_width * min_height) / (CANVAS_SIZE * CANVAS_SIZE) * 100\n",
        "    \n",
        "    print(f\"\\nâš ï¸  æ¨å¥¨å€¤ã¨ã®æ¯”è¼ƒ:\")\n",
        "    print(f\"  æœ€å°bboxã‚µã‚¤ã‚º: {min_width:.1f}x{min_height:.1f} px ({min_area_ratio:.2f}%)\")\n",
        "    if min_width < MIN_BBOX_SIZE or min_height < MIN_BBOX_SIZE:\n",
        "        print(f\"  âš ï¸  è­¦å‘Š: æœ€å°bboxãŒ{MIN_BBOX_SIZE}pxæœªæº€ã§ã™ï¼ˆå­¦ç¿’ã«å½±éŸ¿ãŒã‚ã‚‹å¯èƒ½æ€§ï¼‰\")\n",
        "        print(f\"     MIN_SCALEã‚’å¤§ããã™ã‚‹ã‹ã€MIN_BBOX_SIZEã‚’èª¿æ•´ã—ã¦ãã ã•ã„\")\n",
        "    else:\n",
        "        print(f\"  âœ“ æœ€å°bboxã‚µã‚¤ã‚ºã¯{MIN_BBOX_SIZE}pxä»¥ä¸Šã§ã™\")\n",
        "    \n",
        "    if avg_area_ratio < 0.5:\n",
        "        print(f\"  âš ï¸  è­¦å‘Š: å¹³å‡é¢ç©ãŒ0.5%æœªæº€ã§ã™ï¼ˆbboxãŒå°ã•ã™ãã‚‹å¯èƒ½æ€§ï¼‰\")\n",
        "        print(f\"     MIN_SCALEã‚’å¤§ããã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™\")\n",
        "    else:\n",
        "        print(f\"  âœ“ å¹³å‡é¢ç©ã¯0.5%ä»¥ä¸Šã§ã™ï¼ˆå­¦ç¿’ã«é©ã—ãŸã‚µã‚¤ã‚ºï¼‰\")\n",
        "    \n",
        "    # ã‚µã‚¤ã‚ºåˆ†å¸ƒã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ \n",
        "    print(f\"\\nğŸ“Š ã‚µã‚¤ã‚ºåˆ†å¸ƒ:\")\n",
        "    print(f\"  å¹…ã®åˆ†å¸ƒ:\")\n",
        "    print(f\"    < 32px: {sum(1 for w in bbox_widths if w < 32)} ä»¶ ({sum(1 for w in bbox_widths if w < 32)/len(bbox_widths)*100:.1f}%)\")\n",
        "    print(f\"    32-64px: {sum(1 for w in bbox_widths if 32 <= w < 64)} ä»¶ ({sum(1 for w in bbox_widths if 32 <= w < 64)/len(bbox_widths)*100:.1f}%)\")\n",
        "    print(f\"    64-128px: {sum(1 for w in bbox_widths if 64 <= w < 128)} ä»¶ ({sum(1 for w in bbox_widths if 64 <= w < 128)/len(bbox_widths)*100:.1f}%)\")\n",
        "    print(f\"    >= 128px: {sum(1 for w in bbox_widths if w >= 128)} ä»¶ ({sum(1 for w in bbox_widths if w >= 128)/len(bbox_widths)*100:.1f}%)\")\n",
        "else:\n",
        "    print(\"  âš ï¸  bboxãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\")\n",
        "\n",
        "print(f\"\\nâœ“ bboxã‚µã‚¤ã‚ºçµ±è¨ˆç¢ºèªå®Œäº†\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼ï¼ˆå¯è¦–åŒ–ï¼‰\n",
        "# ============================================\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼ï¼ˆå¯è¦–åŒ–ï¼‰\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚µãƒ³ãƒ—ãƒ«ã‚’é¸ã‚“ã§è¡¨ç¤º\n",
        "num_samples = 5\n",
        "generated_images = list(TRAIN_IMAGES_DIR.glob(\"*.png\"))\n",
        "if len(generated_images) == 0:\n",
        "    print(\"âš ï¸  ç”Ÿæˆã•ã‚ŒãŸç”»åƒãŒã‚ã‚Šã¾ã›ã‚“\")\n",
        "else:\n",
        "    sample_images = random.sample(generated_images, min(num_samples, len(generated_images)))\n",
        "    \n",
        "    print(f\"\\nã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤ºï¼ˆ{len(sample_images)}ä»¶ï¼‰:\")\n",
        "    print(f\"  ç”»åƒã‚µã‚¤ã‚º: {CANVAS_SIZE}x{CANVAS_SIZE} pxï¼ˆå®Ÿéš›ã®ã‚µã‚¤ã‚ºã§è¡¨ç¤ºï¼‰\")\n",
        "    \n",
        "    # 640x640ã®ç”»åƒã‚’é©åˆ‡ã«è¡¨ç¤ºã™ã‚‹ãŸã‚ã®figsizeè¨­å®š\n",
        "    # 1ç”»åƒã‚ãŸã‚Šã®ã‚µã‚¤ã‚º: å¹…8ã‚¤ãƒ³ãƒã€é«˜ã•8ã‚¤ãƒ³ãƒï¼ˆã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”1:1ï¼‰\n",
        "    fig_width = 8\n",
        "    fig_height = 8 * len(sample_images)\n",
        "    fig, axes = plt.subplots(len(sample_images), 1, figsize=(fig_width, fig_height))\n",
        "    if len(sample_images) == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    for idx, img_path in enumerate(sample_images):\n",
        "        # ç”»åƒã‚’èª­ã¿è¾¼ã¿\n",
        "        img = Image.open(img_path)\n",
        "        img_width, img_height = img.size\n",
        "        \n",
        "        # ç”»åƒã‚µã‚¤ã‚ºã‚’ç¢ºèªï¼ˆ640x640ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªï¼‰\n",
        "        if img_width != CANVAS_SIZE or img_height != CANVAS_SIZE:\n",
        "            print(f\"  âš ï¸  è­¦å‘Š: {img_path.name} ã®ã‚µã‚¤ã‚ºãŒ{CANVAS_SIZE}x{CANVAS_SIZE}ã§ã¯ã‚ã‚Šã¾ã›ã‚“ ({img_width}x{img_height})\")\n",
        "        \n",
        "        # ãƒ©ãƒ™ãƒ«ã‚’èª­ã¿è¾¼ã¿\n",
        "        label_path = TRAIN_LABELS_DIR / f\"{img_path.stem}.txt\"\n",
        "        labels = []\n",
        "        if label_path.exists():\n",
        "            with open(label_path, 'r') as f:\n",
        "                for line in f:\n",
        "                    parts = line.strip().split()\n",
        "                    if len(parts) >= 5:\n",
        "                        class_id = int(parts[0])\n",
        "                        center_x = float(parts[1])\n",
        "                        center_y = float(parts[2])\n",
        "                        width = float(parts[3])\n",
        "                        height = float(parts[4])\n",
        "                        \n",
        "                        # YOLOå½¢å¼ã‹ã‚‰ãƒ”ã‚¯ã‚»ãƒ«åº§æ¨™ã«å¤‰æ›\n",
        "                        x_center = center_x * img_width\n",
        "                        y_center = center_y * img_height\n",
        "                        bbox_width = width * img_width\n",
        "                        bbox_height = height * img_height\n",
        "                        \n",
        "                        xmin = x_center - bbox_width / 2\n",
        "                        ymin = y_center - bbox_height / 2\n",
        "                        xmax = x_center + bbox_width / 2\n",
        "                        ymax = y_center + bbox_height / 2\n",
        "                        \n",
        "                        class_name = \"(\" if class_id == CLASS_ID_LPAREN else \")\" if class_id == CLASS_ID_RPAREN else f\"class_{class_id}\"\n",
        "                        labels.append({\n",
        "                            'class_id': class_id,\n",
        "                            'class_name': class_name,\n",
        "                            'bbox': (xmin, ymin, xmax, ymax)\n",
        "                        })\n",
        "        \n",
        "        # ç”»åƒã‚’è¡¨ç¤ºï¼ˆ640x640ã®å®Ÿéš›ã®ã‚µã‚¤ã‚ºã§è¡¨ç¤ºï¼‰\n",
        "        ax = axes[idx]\n",
        "        ax.imshow(img)\n",
        "        ax.set_xlim(0, img_width)\n",
        "        ax.set_ylim(img_height, 0)  # Yè»¸ã‚’åè»¢ï¼ˆç”»åƒåº§æ¨™ç³»ï¼‰\n",
        "        ax.set_aspect('equal')  # ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’1:1ã«ä¿ã¤\n",
        "        ax.axis('off')\n",
        "        \n",
        "        # ã‚°ãƒªãƒƒãƒ‰ã‚’è¡¨ç¤ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼šbboxã‚µã‚¤ã‚ºã‚’ç¢ºèªã—ã‚„ã™ãã™ã‚‹ï¼‰\n",
        "        # ax.grid(True, alpha=0.3, linestyle='--')\n",
        "        \n",
        "        # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’æç”»\n",
        "        for label in labels:\n",
        "            class_id = label['class_id']\n",
        "            class_name = label['class_name']\n",
        "            xmin, ymin, xmax, ymax = label['bbox']\n",
        "            \n",
        "            # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹\n",
        "            color = 'red' if class_id == CLASS_ID_LPAREN else 'blue'\n",
        "            rect = patches.Rectangle(\n",
        "                (xmin, ymin), xmax - xmin, ymax - ymin,\n",
        "                linewidth=2, edgecolor=color,\n",
        "                facecolor='none'\n",
        "            )\n",
        "            ax.add_patch(rect)\n",
        "            \n",
        "            # ã‚¯ãƒ©ã‚¹åã‚’è¡¨ç¤º\n",
        "            ax.text(\n",
        "                xmin, ymin - 5, class_name,\n",
        "                color=color,\n",
        "                fontsize=12, fontweight='bold',\n",
        "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7)\n",
        "            )\n",
        "        \n",
        "        # ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆbboxã‚µã‚¤ã‚ºæƒ…å ±ã‚‚å«ã‚ã‚‹ï¼‰\n",
        "        title = f\"UUID: {img_path.stem[:20]}... | æ¤œå‡ºæ•°: {len(labels)}\"\n",
        "        if len(labels) > 0:\n",
        "            classes_found = [l['class_name'] for l in labels]\n",
        "            title += f\" | ã‚¯ãƒ©ã‚¹: {', '.join(set(classes_found))}\"\n",
        "            # bboxã‚µã‚¤ã‚ºæƒ…å ±ã‚’è¿½åŠ \n",
        "            if len(labels) > 0:\n",
        "                first_bbox = labels[0]['bbox']\n",
        "                bbox_w = first_bbox[2] - first_bbox[0]\n",
        "                bbox_h = first_bbox[3] - first_bbox[1]\n",
        "                bbox_area_ratio = (bbox_w * bbox_h) / (img_width * img_height) * 100\n",
        "                title += f\"\\nbboxã‚µã‚¤ã‚º: {bbox_w:.0f}x{bbox_h:.0f}px ({bbox_w/img_width*100:.1f}% x {bbox_h/img_height*100:.1f}%, é¢ç©: {bbox_area_ratio:.2f}%)\"\n",
        "                # æ¨å¥¨å€¤ã¨ã®æ¯”è¼ƒ\n",
        "                if bbox_w < MIN_BBOX_SIZE or bbox_h < MIN_BBOX_SIZE:\n",
        "                    title += f\" âš ï¸ å°ã•ã™ãã‚‹\"\n",
        "                elif bbox_area_ratio < 0.5:\n",
        "                    title += f\" âš ï¸ é¢ç©ãŒå°ã•ã„\"\n",
        "                else:\n",
        "                    title += f\" âœ“ é©åˆ‡\"\n",
        "        ax.set_title(title, fontsize=10, fontweight='bold')\n",
        "        \n",
        "        # ç”»åƒã‚µã‚¤ã‚ºã®æƒ…å ±ã‚’è¡¨ç¤º\n",
        "        ax.text(10, img_height - 20, f\"ç”»åƒã‚µã‚¤ã‚º: {img_width}x{img_height}px\", \n",
        "                fontsize=9, color='gray', \n",
        "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7))\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(f\"\\nâœ“ æ¤œè¨¼å®Œäº†\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ã‚»ãƒ«7: taråŒ–ï¼ˆS3ä¿ç®¡ç”¨ï¼‰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# taråŒ–ï¼ˆS3ä¿ç®¡ç”¨ï¼‰\n",
        "# ============================================\n",
        "\n",
        "import tarfile\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"taråŒ–ï¼ˆS3ä¿ç®¡ç”¨ï¼‰\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# tarãƒ•ã‚¡ã‚¤ãƒ«ã®å‡ºåŠ›å…ˆ\n",
        "tar_dir = OUT_DIR.parent / \"paren_tars\"\n",
        "tar_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"\\nå‡ºåŠ›å…ˆ: {tar_dir}\")\n",
        "\n",
        "# tarãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹\n",
        "train_images_tar = tar_dir / \"paren_train_images.tar\"\n",
        "train_labels_tar = tar_dir / \"paren_train_labels.tar\"\n",
        "\n",
        "def create_tar(source_dir, tar_path, desc):\n",
        "    \"\"\"tarãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ\"\"\"\n",
        "    start_time = time.time()\n",
        "    print(f\"\\nğŸ“¦ {desc}ã‚’ä½œæˆä¸­...\")\n",
        "    \n",
        "    with tarfile.open(tar_path, 'w') as tar:\n",
        "        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ \n",
        "        files = list(source_dir.rglob('*'))\n",
        "        for file_path in tqdm(files, desc=desc):\n",
        "            if file_path.is_file():\n",
        "                # ç›¸å¯¾ãƒ‘ã‚¹ã§è¿½åŠ \n",
        "                arcname = file_path.relative_to(source_dir)\n",
        "                tar.add(file_path, arcname=arcname)\n",
        "    \n",
        "    elapsed = time.time() - start_time\n",
        "    size_mb = tar_path.stat().st_size / (1024 * 1024)\n",
        "    print(f\"  âœ“ å®Œäº†: {tar_path.name} ({size_mb:.2f} MB, {elapsed:.1f}ç§’)\")\n",
        "    return size_mb\n",
        "\n",
        "# train_images.tar\n",
        "if not train_images_tar.exists() or FORCE_REBUILD_TAR:\n",
        "    if train_images_tar.exists() and FORCE_REBUILD_TAR:\n",
        "        print(f\"\\nğŸ”„ FORCE_REBUILD_TAR=True ã®ãŸã‚ã€æ—¢å­˜ã®tarãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ä½œæˆã—ã¾ã™\")\n",
        "        train_images_tar.unlink()\n",
        "    create_tar(TRAIN_IMAGES_DIR, train_images_tar, \"paren_train_images.tar\")\n",
        "else:\n",
        "    size_mb = train_images_tar.stat().st_size / (1024 * 1024)\n",
        "    print(f\"\\nâœ“ paren_train_images.tar ã¯æ—¢ã«å­˜åœ¨: {size_mb:.2f} MB\")\n",
        "    print(f\"  âš ï¸  å†ä½œæˆã™ã‚‹å ´åˆã¯ã€FORCE_REBUILD_TAR=True ã«è¨­å®šã—ã¦ãã ã•ã„\")\n",
        "\n",
        "# train_labels.tar\n",
        "if not train_labels_tar.exists() or FORCE_REBUILD_TAR:\n",
        "    if train_labels_tar.exists() and FORCE_REBUILD_TAR:\n",
        "        print(f\"\\nğŸ”„ FORCE_REBUILD_TAR=True ã®ãŸã‚ã€æ—¢å­˜ã®tarãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ä½œæˆã—ã¾ã™\")\n",
        "        train_labels_tar.unlink()\n",
        "    create_tar(TRAIN_LABELS_DIR, train_labels_tar, \"paren_train_labels.tar\")\n",
        "else:\n",
        "    size_mb = train_labels_tar.stat().st_size / (1024 * 1024)\n",
        "    print(f\"\\nâœ“ paren_train_labels.tar ã¯æ—¢ã«å­˜åœ¨: {size_mb:.2f} MB\")\n",
        "    print(f\"  âš ï¸  å†ä½œæˆã™ã‚‹å ´åˆã¯ã€FORCE_REBUILD_TAR=True ã«è¨­å®šã—ã¦ãã ã•ã„\")\n",
        "\n",
        "# åˆè¨ˆã‚µã‚¤ã‚º\n",
        "total_size = sum(f.stat().st_size for f in [train_images_tar, train_labels_tar] if f.exists())\n",
        "total_size_mb = total_size / (1024 * 1024)\n",
        "print(f\"\\nâœ“ taråŒ–å®Œäº†\")\n",
        "print(f\"  åˆè¨ˆã‚µã‚¤ã‚º: {total_size_mb:.2f} MB\")\n",
        "print(f\"  å‡ºåŠ›å…ˆ: {tar_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ã‚»ãƒ«8: S3ã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆä»»æ„ï¼‰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# S3ã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆä»»æ„ï¼‰\n",
        "# ============================================\n",
        "\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "if not UPLOAD_TO_S3:\n",
        "    print(\"âš ï¸  UPLOAD_TO_S3=False ã®ãŸã‚ã€S3ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™\")\n",
        "else:\n",
        "    print(\"=\" * 80)\n",
        "    print(\"S3ã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # AWSèªè¨¼æƒ…å ±ã®ç¢ºèª\n",
        "    try:\n",
        "        result = subprocess.run([\"aws\", \"sts\", \"get-caller-identity\"], \n",
        "                              capture_output=True, text=True, check=True)\n",
        "        print(f\"\\nâœ“ AWSèªè¨¼æƒ…å ±ã‚’ç¢ºèª\")\n",
        "    except subprocess.CalledProcessError:\n",
        "        print(\"\\nâŒ ã‚¨ãƒ©ãƒ¼: AWSèªè¨¼æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“\")\n",
        "        print(\"   ã‚»ãƒ«0ã§AWSèªè¨¼æƒ…å ±ã‚’è¨­å®šã—ã¦ãã ã•ã„\")\n",
        "        raise\n",
        "    \n",
        "    tar_files = [\n",
        "        (train_images_tar, \"paren_train_images.tar\"),\n",
        "        (train_labels_tar, \"paren_train_labels.tar\"),\n",
        "    ]\n",
        "    \n",
        "    uploaded = []\n",
        "    failed = []\n",
        "    \n",
        "    for tar_path, tar_name in tar_files:\n",
        "        if not tar_path.exists():\n",
        "            print(f\"\\nâš ï¸  ã‚¹ã‚­ãƒƒãƒ—: {tar_name} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
        "            continue\n",
        "        \n",
        "        s3_path = f\"s3://{S3_BUCKET}/{S3_PREFIX}/{tar_name}\"\n",
        "        \n",
        "        # S3ã«æ—¢ã«å­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯\n",
        "        s3_exists = False\n",
        "        if FORCE_UPLOAD_S3:\n",
        "            try:\n",
        "                result = subprocess.run(\n",
        "                    [\"aws\", \"s3\", \"ls\", s3_path],\n",
        "                    capture_output=True, text=True, check=True\n",
        "                )\n",
        "                s3_exists = True\n",
        "                print(f\"\\nâš ï¸  {tar_name} ã¯æ—¢ã«S3ã«å­˜åœ¨ã—ã¾ã™\")\n",
        "                print(f\"   S3ãƒ‘ã‚¹: {s3_path}\")\n",
        "                print(f\"   FORCE_UPLOAD_S3=True ã®ãŸã‚ã€ä¸Šæ›¸ãã—ã¾ã™\")\n",
        "            except subprocess.CalledProcessError:\n",
        "                s3_exists = False\n",
        "        else:\n",
        "            # FORCE_UPLOAD_S3=False ã®å ´åˆã¯æ—¢å­˜ãƒã‚§ãƒƒã‚¯ã—ã¦ã‚¹ã‚­ãƒƒãƒ—\n",
        "            try:\n",
        "                result = subprocess.run(\n",
        "                    [\"aws\", \"s3\", \"ls\", s3_path],\n",
        "                    capture_output=True, text=True, check=True\n",
        "                )\n",
        "                s3_exists = True\n",
        "                print(f\"\\nâœ“ {tar_name} ã¯æ—¢ã«S3ã«å­˜åœ¨ã—ã¾ã™ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰\")\n",
        "                print(f\"   S3ãƒ‘ã‚¹: {s3_path}\")\n",
        "                print(f\"   FORCE_UPLOAD_S3=False ã®ãŸã‚ã€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™\")\n",
        "                continue\n",
        "            except subprocess.CalledProcessError:\n",
        "                s3_exists = False\n",
        "        \n",
        "        print(f\"\\nğŸ“¤ {tar_name} ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...\")\n",
        "        print(f\"   S3ãƒ‘ã‚¹: {s3_path}\")\n",
        "        \n",
        "        max_retries = 3\n",
        "        retry_count = 0\n",
        "        success = False\n",
        "        \n",
        "        while retry_count < max_retries and not success:\n",
        "            try:\n",
        "                start_time = time.time()\n",
        "                result = subprocess.run(\n",
        "                    [\"aws\", \"s3\", \"cp\", str(tar_path), s3_path],\n",
        "                    capture_output=True, text=True, check=True\n",
        "                )\n",
        "                elapsed = time.time() - start_time\n",
        "                size_mb = tar_path.stat().st_size / (1024 * 1024)\n",
        "                print(f\"  âœ“ å®Œäº†: {size_mb:.2f} MB, {elapsed:.1f}ç§’\")\n",
        "                uploaded.append(tar_name)\n",
        "                success = True\n",
        "            except subprocess.CalledProcessError as e:\n",
        "                retry_count += 1\n",
        "                if retry_count < max_retries:\n",
        "                    print(f\"  âš ï¸  ãƒªãƒˆãƒ©ã‚¤ {retry_count}/{max_retries}...\")\n",
        "                    time.sleep(2)\n",
        "                else:\n",
        "                    print(f\"  âŒ å¤±æ•—: {e.stderr}\")\n",
        "                    failed.append(tar_name)\n",
        "    \n",
        "    print(f\"\\n\" + \"=\" * 80)\n",
        "    print(\"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰çµæœ\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"  æˆåŠŸ: {len(uploaded)} ä»¶\")\n",
        "    if uploaded:\n",
        "        for name in uploaded:\n",
        "            print(f\"    âœ“ {name}\")\n",
        "    \n",
        "    print(f\"  å¤±æ•—: {len(failed)} ä»¶\")\n",
        "    if failed:\n",
        "        for name in failed:\n",
        "            print(f\"    âŒ {name}\")\n",
        "    \n",
        "    if len(uploaded) == len(tar_files):\n",
        "        print(f\"\\nâœ“ å…¨ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸ\")\n",
        "        print(f\"  S3ãƒ‘ã‚¹: s3://{S3_BUCKET}/{S3_PREFIX}/\")\n",
        "    else:\n",
        "        print(f\"\\nâš ï¸  ä¸€éƒ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ\")\n",
        "        print(f\"  å¤±æ•—ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã¯æ‰‹å‹•ã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
